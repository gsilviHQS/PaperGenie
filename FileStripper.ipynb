{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gsilvi/miniforge3/envs/PaperGenie/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "import embedding_functions\n",
    "import functions\n",
    "from PyPDF2 import PdfFileReader\n",
    "import numpy as np\n",
    "from openai.embeddings_utils import get_embedding, cosine_similarity\n",
    "import pandas as pd\n",
    "import openai\n",
    "openai.api_key_path = \"API.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#complete_text = functions.extract_all_text(['papers/1801.00862/NISQ-Quantum.tex']) \n",
    "complete_text = functions.extract_all_text(['papers/2201.08194/BP_shadows.tex']) \n",
    "#complete_text = functions.extract_all_text(['papers/2002.12902/main.tex']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['pre_section', 'Introduction', 'Avoiding barren plateaus in variational quantum optimization', 'Variational quantum eigensolver', 'Barren plateaus and entanglement', 'Weak barren plateaus and improved algorithm', 'Weak barren plateaus and initialization of VQE', 'Definition and relation to barren plateaus ', 'Illustration of WBP-free initialization', 'Entanglement control during optimization', 'Bounding entanglement increase at a single optimization step', 'Optimization performance with learning rate', 'Summary and Discussion', 'Acknowledgments', 'Appendix', 'Classical shadows and implementation details', 'Data acquisition via classical shadows', 'Estimating subsystem purities', 'Estimating gradients', 'Example of error accumulation in an Ising model', 'Proof of Theorem~\\\\ref{thm:linear-shadows} \\\\labelSec:proof', 'Unitary \\\\texorpdfstring{$t$}--designs}\\\\labelappx:t-design', 'Entanglement and unitary \\\\texorpdfstring{$2$}--designs}\\\\labelapp:ent', 'Bounding the expected trace distance', \"Bounding the expected second R\\\\'enyi entropy\", 'Entanglement growth and learning rate'])\n",
      "Introduction\n",
      "Avoiding barren plateaus in variational quantum optimization\n",
      "Variational quantum eigensolver\n",
      "Barren plateaus and entanglement\n",
      "Weak barren plateaus and improved algorithm\n",
      "Weak barren plateaus and initialization of VQE\n",
      "Definition and relation to barren plateaus \n",
      "Illustration of WBP-free initialization\n",
      "Entanglement control during optimization\n",
      "Bounding entanglement increase at a single optimization step\n",
      "Optimization performance with learning rate\n",
      "Summary and Discussion\n",
      "Acknowledgments\n",
      "Appendix\n",
      "Classical shadows and implementation details\n",
      "Data acquisition via classical shadows\n",
      "Estimating subsystem purities\n",
      "Estimating gradients\n",
      "Example of error accumulation in an Ising model\n",
      "Proof of Theorem~\\ref{thm:linear-shadows} \\labelSec:proof\n",
      "Unitary \\texorpdfstring{$t$}--designs}\\labelappx:t-design\n",
      "Entanglement and unitary \\texorpdfstring{$2$}--designs}\\labelapp:ent\n",
      "Bounding the expected trace distance\n",
      "Bounding the expected second R\\'enyi entropy\n",
      "Entanglement growth and learning rate\n"
     ]
    }
   ],
   "source": [
    "final_text = embedding_functions.texStripper(complete_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['title: Avoiding barren plateaus using classical shadows',\n",
       " 'author: Stefan H. Sack,Raimel A. Medina,Alexios A. Michailidis,Richard Kueng,Maksym Serbyn',\n",
       " 'thanks: Equal contribution,Equal contribution',\n",
       " 'email: stefan.sack@ist.ac.at,raimel.medina@ist.ac.at',\n",
       " 'affiliation: IST Austria, Am Campus 1, 3400 Klosterneuburg, Austria,IST Austria, Am Campus 1, 3400 Klosterneuburg, Austria,Department of Theoretical Physics, University of Geneva,24 quai Ernest-Ansermet, 1211 Geneva, Switzerland,Institute for Integrated Circuits, Johannes Kepler University Linz, Austria,IST Austria, Am Campus 1, 3400 Klosterneuburg, Austria',\n",
       " 'Abstract: Variational quantum algorithms are promising algorithms for achieving quantum advantage on near-term devices. The quantum hardware is used to implement a variational wave function and measure observables, whereas the classical computer is used to store and update the variational parameters. The optimization landscape of expressive variational ans\\\\\"atze is however dominated by large regions in parameter space, known as barren plateaus, with vanishing gradients which prevents efficient optimization. In this work we propose a general algorithm to avoid barren plateaus in the initialization and throughout the optimization. To this end we define a notion of \\\\emph{weak barren plateaus} (WBP) based on the entropies of local reduced density matrices. The presence of WBPs can be efficiently quantified using recently introduced shadow tomography of the quantum state with a classical computer. We demonstrate that avoidance of WBPs suffices to ensure sizable gradients in the initialization. In addition, we demonstrate that decreasing the gradient step size, guided by the entropies allows to avoid WBPs during the optimization process. This paves the way for efficient barren plateau free optimization on near-term devices.',\n",
       " 'In recent years the field of quantum computation has seen rapid growth fueled by the arrival of the first generation of quantum computers, dubbed noisy intermediate-scale quantum devices (NISQ)~\\\\cite{preskill2018quantum}',\n",
       " 'The NISQ era is characterized by quantum computers with a small number of qubits and limited control',\n",
       " \"The number of coherent operations that can be performed is small and the implementation of famous algorithms with proven quantum speedups, such as Shor's algorithm~\\\\cite{shor}, remains out of reach\",\n",
       " 'To make use of the current generation of quantum computers,  the so called variational hybrid approach~\\\\cite{nisq} was proposed',\n",
       " 'The idea is to use the quantum computer in a feedback loop with a classical computer, where it implements a variational wave function that is measured to compute the value of the so-called cost function',\n",
       " 'This information is then fed into a classical computer where it is processed and the variational wave function is subsequently updated aiming to find a minimum of the cost function, which provides an (approximate) solution to the computationally hard problem',\n",
       " 'The variational hybrid approach has seen a wide range of proof of concept applications on NISQ devices ranging from quantum chemistry~\\\\cite{kandala2017hardware, arute2020hartree} to quantum optimization~\\\\cite{harrigan2021quantum, lacriox2020improving} and quantum machine learning~\\\\cite{havlicek2019supervised, johri2021nearest}.Despite the large number of suggested applications, the variational approach encountered also  a number of obstacles, that have to be overcome for the future success of the method',\n",
       " 'In particular, the infamous emergence of \\\\textit{barren plateaus} (BPs) implies that expressive variational ans\\\\\"atze tend to be exponentially hard to optimize~\\\\cite{mcclean2018barren}',\n",
       " 'The main obstacle on the way to optimization lies in the fact that gradients of the cost function are on average zero and deviations vanish exponentially in system size, thus precluding any potential quantum advantage',\n",
       " 'Moreover, it has been shown that the classical optimization problem is generally NP-hard and plagued with many local minima~\\\\cite{bittel2021training}',\n",
       " 'The problem of BPs attracted significant attention, and numerous approaches were proposed in the literature',\n",
       " 'In particular, the early research focused on avoidance of BP at the \\\\emph{initialization stage} of variational algorithms~\\\\cite{grant2019initialization, skolik2020layerwise, dborin2021matrix, holmes2021connecting}',\n",
       " 'In a different direction, the relation between occurrence of BPs and the structure of the cost function was studied~\\\\cite{cerezo2020cost, uvarov2020barren}',\n",
       " 'Also notions of so-called entanglement-induced~\\\\cite{marrero2020entanglement} and noise-induced~\\\\cite{wang2020noise} BPs were introduced',\n",
       " 'The relation between BPs and entanglement has lead to various proposals that suggest controlling entanglement to mitigate BPs~\\\\cite{kim2021entanglement, kim2021quantum, patti2021entanglement, wiersema2021measurement-induced}',\n",
       " 'However, measuring entanglement is hard, therefore making these approaches impractical on a real quantum device',\n",
       " 'In this work we introduce the notion of \\\\textit{weak barren plateaus} (WBPs), in order to diagnose and avoid BPs in variational quantum optimization',\n",
       " 'WBPs emerge when the entanglement of a local subsystem exceeds a certain threshold identified by the entanglement of a fully scrambled state.In contrast to BPs, WBPs can be efficiently diagnosed using the few-body density matrices and we show that their absence is a sufficient condition for avoiding BPs',\n",
       " 'Based on the notion of WBPs, we propose an algorithm  that can be readily implemented on available NISQ devices',\n",
       " \"The algorithm employs  \\\\emph{classical shadow} estimation~\\\\cite{huang2020predicting} during the optimization process in order to efficiently estimate the expectation value of the cost function, its  gradients, and the second R\\\\'enyi entropy of small subsystems\",\n",
       " \"The tracking of the second R\\\\'enyi entropy enabled by the classical shadows protocol allows for an efficient diagnosis of the WBP both at the initialization step  and during the optimization process of variational parameters\",\n",
       " \"If the algorithm encounters a WBP, as witnessed by a certain subregion having a sufficiently large R\\\\'enyi entropy, the algorithm restarts the optimization process with a decreased value of the update step (controlled by the so-called learning rate)\",\n",
       " 'We support the proposed procedure by rigorous results and numerical simulations',\n",
       " 'Mathematically, we show that if the unitary circuit used in the variational algorithm forms the so-called 2-design~\\\\cite{renes2004symmetric, dankert2009exact, harrow2009random}, implying emergence of a BP~\\\\cite{mcclean2018barren}, this also automatically implies that the system is in a WBP',\n",
       " 'This result supports the use of WBPs as a sufficient criterion for avoiding BPs on average',\n",
       " 'In addition, we construct the bound for the increase in the purity of subsystems in the process of optimization',\n",
       " \"This bound and the relation between purity and the second R\\\\'enyi entropy, imply the existence of a sufficiently small learning rate that avoids WBPs during the the update process\",\n",
       " 'Phenomenologically, we perform numerical simulations of the variational preparation of the ground state of the Heisenberg model',\n",
       " 'While the issue of avoiding BPs at the initialization received considerable attention, the emergence and role of BPs \\\\textit{during} the optimization process is still unclear',\n",
       " 'We observe that BPs can also emerge during the optimization procedure, especially if the learning rate is chosen too large',\n",
       " 'Although we construct an analytical guarantee for an existence of an appropriate learning rate to perform a single update step without getting into a WBP, proving the success of the algorithm on the whole remains out of reach',\n",
       " 'Nevertheless, our numerical simulation shows that a few restarts that decrease the learning rate are sufficient for arriving to the variational wave function, with energy close to the ground state of the Heisenberg model',\n",
       " 'We also find that while the choice of an extremely small learning rate avoids a WBP, it also hinders the performance.The structure of the paper is as follows: in Sec.~\\\\ref{sec:2} we introduce the variational quantum eigensolver (VQE) and discuss the issue of  BPs',\n",
       " 'Afterwards we present our main results: the definition of WBPs and a VQE algorithm that uses local entanglement to avoid WBPs',\n",
       " 'The remainder of the paper is devoted to justification of the proposed algorithm and numerical tests',\n",
       " 'To this end, in Sec.~\\\\ref{sec:3} we show that avoiding WBPs is sufficient for the avoidance of BPs, and demonstrate this numerically for the popular BP-free initialization~\\\\cite{holmes2021connecting, haug2021capacity}',\n",
       " 'In Sec.~\\\\ref{sec:4} we justify the approach to avoidance of BPs during the optimization using bounds on purity increase via quantum Fischer information',\n",
       " 'In addition, we heuristically compare the optimization performance for different learning rates',\n",
       " 'Finally, in Sec.~\\\\ref{sec:5} we summarize our results, discuss their implications, and outline open questions',\n",
       " 'In this section we first introduce  the framework of VQEs, i.e',\n",
       " 'the unitary ensemble, the cost functions and the optimization algorithm, and discuss the BP problem',\n",
       " ' After this, we present our main result -- a specific modification of the variational quantum eigensolver (VQE) that avoids the issue of BPs.',\n",
       " 'The aim of the VQE, initially introduced by~\\\\citeauthor{peruzzo2014VQE}, is to approximate the ground state $\\\\ket{GS}$ of a Hamiltonian $H$ with a variational wave function $\\\\ket{\\\\psi(\\\\bm{\\\\theta})}$',\n",
       " 'A quantum computer is used to prepare the variational function via the action of a set of unitary gates, $\\\\ket{\\\\psi(\\\\bm{\\\\theta})} = U(\\\\bm{\\\\theta}) \\\\ket{\\\\psi_0}$, where $\\\\ket{\\\\psi_0}$ is the initial state that is typically assumed to be a product state',\n",
       " 'The variational parameters are then iteratively updated to minimize the expectation value of the Hamiltonian, also called cost function $E(\\\\bm{\\\\theta})=\\\\bra{\\\\psi(\\\\bm{\\\\theta})} H \\\\ket{\\\\psi(\\\\bm{\\\\theta})}$.We consider a unitary circuit $U(\\\\bm{\\\\theta})$ of the form of the so-called ``hardware-efficient\" ansatz~\\\\cite{kandala2017hardware}\\\\begin{equation}\\\\label{eq:ruc}    U(\\\\bm{\\\\theta}) = \\\\prod_{l=1}^{p}  W_l\\\\bigg( \\\\prod_{i=1}^{N} R_l^i(\\\\theta_l^i) \\\\bigg ),\\\\end{equation}where $\\\\theta_l^i \\\\in [-\\\\pi, \\\\pi)$ are $p N$ variational angles, concisely denoted as $\\\\bm \\\\theta$',\n",
       " \"In this expression the product goes over spatial dimension $i=1,\\\\ldots,N$ that labels individual qubits and ``time dimension'', $l = 1,\\\\ldots, p$ with $p$ specifying a number of layers, see Fig.~\\\\ref{fig:1}(a)\",\n",
       " 'We choose the single qubit gates to be rotations $R_l^i(\\\\theta_l^i)=\\\\exp(-\\\\frac{\\\\im}{2} \\\\theta_l^i G_{l,i})$ with random directions given by $G_{l,i} \\\\in \\\\{\\\\sigma^x, \\\\sigma^y, \\\\sigma^y \\\\}$',\n",
       " '$W_l$ is an entangling layer that consists of two qubit entangling gates represented by nearest-neighbor controlled-Z (CZ) gates with periodic boundary conditions, see Fig.~\\\\ref{fig:1}(a) for an illustration',\n",
       " '\\\\begin{figure*}[t]    \\\\centering    \\\\includegraphics[width=1.99\\\\columnwidth]{figures/fig1.pdf}    \\\\caption{(a) Illustration of the variational quantum circuit $U(\\\\bm{\\\\theta}) \\\\ket{0}$ that is considered in the main text followed by the shadow tomography scheme~\\\\cite{huang2020predicting}',\n",
       " 'The variational circuit consists of alternating layers of single qubit rotations represented as boxes and entangling CZ gates shown by lines',\n",
       " 'The measurements at the end are used to estimate values of the cost function, its gradients, and other quantities',\n",
       " '(b) The original hybrid variational quantum algorithm shown by solid boxes can be modified without incurring significant overhead as is shown by the dashed lines and boxes',\n",
       " 'The modified algorithm tracks entanglement of small subregions and restarts the algorithm if it exceeds the fraction of the Page value that is set by parameter $\\\\alpha$',\n",
       " 'Here we choose $\\\\alpha=0.5$ indicated by the grey dashed line, see the last paragraph of Sec.~\\\\ref{sec:3a} for a discussion on the choice of $\\\\alpha$',\n",
       " '    (c-e) The application of the proposed algorithm to the problem of finding the ground state of the Heisenberg model',\n",
       " 'For large learning rates $\\\\eta=1$ and $0.1$ (red and blue lines) the optimization gets into a large entanglement region as is shown in panel (d), indicated by colored stars, forcing the restart of the optimization with smaller value of $\\\\eta$',\n",
       " 'For $\\\\eta=0.01$ the algorithm avoids large entanglement region and gets a good approximation for the ground state',\n",
       " 'Finally, setting even smaller learning rate (green lines) degrades the performance',\n",
       " \"The normalized second R\\\\'enyi entropy of the true ground state is $S_2/S^{\\\\text{Page}} (k, N)  \\\\approx 0.246$\",\n",
       " '(e) Shows the corresponding gradient norm',\n",
       " 'A small gradient norm equally corresponds to the BP and the good local minima found with $\\\\eta=0.01$ and $0.001$',\n",
       " 'We use a system size of $N=10$, subsystem size $k=2$ and a random circuit (see Eq.~(\\\\ref{eq:ruc})) with circuit depth $p=100$ and small qubit rotations ($\\\\epsilon_{{\\\\theta}}=0.05$) to generate a BP-free initialization',\n",
       " 'Data was averaged over $100$ random instances.}    \\\\label{fig:1}\\\\end{figure*}We focus our study on $k$-local Hamiltonians $H$, defined as sum of terms each containing at most $k$ Pauli matrices',\n",
       " 'We take $k$ to be finite and fixed, while the number of qubits $N\\\\gg k$',\n",
       " 'A particular example of $2$-local Hamiltonian from the many-body physics is provided by the Heisenberg model subject to a magnetic field,\\\\begin{equation}\\\\label{eq:heisenberg}\\tH = \\\\sum_{i=1}^N J \\\\big(\\\\sigma_i^z \\\\sigma_{i+1}^z + \\\\sigma_i^y \\\\sigma_{i+1}^y + \\\\sigma_i^x \\\\sigma_{i+1}^x\\\\big)\\t+ h_z \\\\sum_{i=1}^N \\\\sigma_i^z,\\\\end{equation}where the couplings are fixed $J=h_z=1$',\n",
       " 'This particular example of a 2-local Hamiltonian also exhibits a spatial locality, that is convenient but not required for our results to hold',\n",
       " 'In addition, the $U(1)$ symmetry related to the conservation of $z$-component of spin under the action of $H$ can be explored to decrease the space of parameters by using a suitable gate set respecting this symmetry',\n",
       " 'However, for the sake of generality we focus on the hardware-efficient unitary ansatz defined in  Eq.~\\\\eqref{eq:ruc}',\n",
       " 'Obtaining the energy expectation value $E(\\\\bm{\\\\theta}) =\\\\bra{\\\\psi(\\\\bm{\\\\theta})} H \\\\ket{\\\\psi(\\\\bm{\\\\theta})}$ requires measuring a subset or all qubits in the circuit as we schematically show in Fig.~\\\\ref{fig:1}(a)',\n",
       " 'For our example of $2$-local Hamiltonian, the required measurements include value of $\\\\sigma^z$ operator on all sites along with the $\\\\sigma_i^a \\\\sigma_{i+1}^a$ expectation values of all $i=1,\\\\ldots N$ (periodic boundary condition is assumed, so that bits $1$ and $N+1$ are identified) and $a=x,y,z$',\n",
       " 'Finding the optimal parameters $\\\\bm{\\\\theta}^\\\\star$ requires minimization of the Hamiltonian expectation value $E(\\\\bm{\\\\theta}^\\\\star)=\\\\min_{\\\\bm{\\\\theta}}E(\\\\bm{\\\\theta})$ performed by a classical computer',\n",
       " 'There is a plethora of sophisticated classical optimization algorithms that were applied to this minimization problem~\\\\cite{ostaszewski2021structure, stokes2020quantum, adam, gacon2021simultaneous}',\n",
       " 'We use the plain gradient descent (GD) algorithm due to its simplicity which makes analytical considerations easier',\n",
       " 'A GD update step is given by\\\\begin{equation}\\\\label{eq:gd}\\t\\\\bm{\\\\theta}^{t+1} = \\\\bm{\\\\theta}^t - \\\\eta \\\\nabla_{\\\\bm{\\\\theta}} E(\\\\bm{\\\\theta}),\\\\end{equation}where $\\\\eta$ is the \\\\textit{learning rate} which controls the update magnitude',\n",
       " 'This update step is repeated until convergence of $E(\\\\bm{\\\\theta})$ which results from finding a (local) minimum of $E(\\\\bm{\\\\theta})$.The resulting VQE algorithm is shown schematically in Fig.~\\\\ref{fig:1}(b) by solid lines',\n",
       " 'Following the initialization of the variational angles $\\\\bm \\\\theta$, that may be chosen to be real random numbers, the quantum computer is used to prepare the variational state and provide quantum measurement results',\n",
       " 'The classical computer uses the measurements to estimate the value of the cost function and its gradient, and performs an update of the variational parameters controlled by the learning rate~$\\\\eta$',\n",
       " ' ',\n",
       " 'Whilst the VQE described above is a promising framework for near-term quantum computing due to its modest hardware requirements, its performance may be ruined by the issue of barren plateaus~\\\\cite{mcclean2018barren, cerezo2020cost, holmes2021connecting}',\n",
       " 'Specifically, the BPs are defined as regions in the space of variational parameters where  the variance of the cost function gradient (and consequently its typical value) vanishes exponentially in the number of qubits~\\\\cite{mcclean2018barren}: \\\\begin{equation}\\t\\\\mathop{\\\\rm{Var}}[\\\\partial_{i, l} E(\\\\bm{\\\\theta}) ] \\\\sim \\\\mathcal{O}\\\\left(\\\\frac{1}{2^{2N}}\\\\right)',\n",
       " '\\\\end{equation}The estimation of such  exponentially small gradient of the cost function requires a number of measurements that is exponential in the number of qubits, and therefore invalidates any potential quantum speedup',\n",
       " '\\\\citeauthor{mcclean2018barren} were among the first to theoretically investigate BPs',\n",
       " 'They showed that the appearance of a BP can be related to the circuit matching the Haar random distribution up to the second moment',\n",
       " 'More precisely, they showed that BPs are a consequence of the unitary ensemble $\\\\mathcal{E}\\\\sim \\\\{U(\\\\bm{\\\\theta})\\\\} _{\\\\bm{\\\\theta}}$ forming a so-called 2-design~\\\\cite{mcclean2018barren} (see Appendix~\\\\ref{appx:t-design} for details and the definition of a $t$-design)',\n",
       " 'To understand the different circuit depth at which BPs are encountered, the authors in Ref.~\\\\cite{cerezo2020cost} introduced the concept of cost function dependent BPs',\n",
       " 'In particular, they argued that the emergence of BP occurs at different circuit depths, depending on the nature of the cost function',\n",
       " 'In contrast, for a so-called global cost function, exemplified by the fidelity, Ref.~\\\\cite{cerezo2020cost} found that BPs already occur at very modest circuit depths $p\\\\sim \\\\mathcal{O}(1)$',\n",
       " 'The emergence of BP for the fidelity is naturally related to ``orthogonality catastrophe\" in many-body physics: even a small global unitary rotation applied to the many-body wave function results in it becoming nearly orthogonal to itself',\n",
       " 'In terms of fidelity, this implies that it vanishes exponentially in the number of qubits',\n",
       " 'Moreover, most global state features -- such as expectation values of general operators, fidelities with general states and global purities -- cannot be efficiently accessed on NISQ devices, and are therefore not practical from an algorithmic point of view~\\\\cite{flammia11direct,huang2020predicting,huang2021learning,chen2021exponential}',\n",
       " 'Therefore, in what follows we do not consider the global cost functions and corresponding BPs.Local cost functions, that are the focus of the present work are characterized by a later onset of BPs',\n",
       " 'Specifically, for a $k$-local cost function where $k$ is fixed, the BPs will occur for circuit depth $p \\\\sim \\\\mathcal{O}({\\\\rm poly}(N))$ that increases polynomially in system size~\\\\cite{mcclean2018barren, cerezo2020cost}',\n",
       " 'In other words, for a large enough $p$ the VQE algorithm will also suffer from a BP already at the very first step of the GD optimization, provided random choice of variational angles $\\\\bm \\\\theta$',\n",
       " 'We also note that gradient-free optimization strategies do not circumvent the BP-problem since the optimization landscape is inherently flat~\\\\cite{arrasmith2021effect}.The potential emergence of BPs at the initialization stage of the VQE and other algorithms spurred the investigation of different initializations strategies that avoid BPs',\n",
       " 'Until now, several BP-free initializations were considered in the literature',\n",
       " 'Ref.~\\\\cite{grant2019initialization} suggests to initialize the circuit with blocks of identities, Ref.~\\\\cite{skolik2020layerwise} suggests to optimize the ansatz layer by layer, and Ref.~\\\\cite{dborin2021matrix} suggests to use an an matrix product state ansatz that is optimized by a separate algorithm~\\\\cite{cirac2020matrix} and map that to a quantum circuit',\n",
       " 'In this work we will focus on small single qubit rotation as suggested in Ref.~\\\\cite{holmes2021connecting}',\n",
       " 'More recently, it was observed that the entanglement entropy defined as a trace of the reduced density matrix, $S=-\\\\tr \\\\rho_A \\\\ln \\\\rho_A$ (where $\\\\rho_A=\\\\tr_B \\\\rho$ is the reduced density matrix where $A$ is the subset of qubits that are measured and $B$ is the rest of the system) is another source for the occurrence of BPs~\\\\cite{marrero2020entanglement}',\n",
       " 'The community has subsequently dubbed this kind of BP, \\\\textit{entanglement induced} BP~\\\\cite{marrero2020entanglement, kim2021entanglement, wiersema2021measurement-induced, patti2021entanglement}',\n",
       " 'In this work, we will however show that entanglement induced BPs and BPs for local cost functions, are in fact one and the same',\n",
       " 'Avoiding entanglement induced BPs is equivalent to avoiding BPs for local cost functions, the details are presented in Sec.~\\\\ref{sec:3}.However, entanglement is not a practical quantity to be used in a quantum algorithm due to high computational costs',\n",
       " 'In addition, the majority of approaches up to date focused on the mitigation of BP at the initialization stage~\\\\cite{grant2019initialization, verdon2019learning, volkoff2021largegradients}',\n",
       " 'In Sec.~\\\\ref{sec:4}, we illustrate the importance of BP mitigation during the optimization',\n",
       " 'This motivates the need to devise a BP mitigation strategy for the initialization and during the optimization procedure that is efficient',\n",
       " 'This procedure will be discussed in the algorithm proposed below',\n",
       " 'In order to devise an efficient algorithm for BP-free initialization and optimization of the VQE we introduce the notion of WBPs',\n",
       " 'Specifically, for a Hamiltonian that is $k$-local, we define the WBP as the point where the second Renyi entropy $S_2=-\\\\ln \\\\tr \\\\rho_A^2 $ of any subregion of $k$-qubits satisfies $S_2 \\\\geq \\\\alpha S^{\\\\text{Page}}(k, N)$, where the Page entropy in the limit $k\\\\ll N$ corresponds to the (nearly) maximal possible entanglement of subregion $A$,\\\\be\\\\label{eq:full_page_asymptotic}S^{\\\\text{Page}}(k, N) \\\\simeq k\\\\ln 2 - \\\\frac{1}{2^{N-2k+1}},\\\\eewhere we explicitly used the Hilbert space dimensions of regions $A$ is $2^k$ and its complement $B$ has Hilbert space dimension $2^{N-k}$',\n",
       " 'The naive choice for the parameter $\\\\alpha$ is $\\\\alpha=1$',\n",
       " 'Given some a priori knowledge of the entanglement structure of the target state $\\\\ket{GS}$, the choice can however be more informed to help avoiding large entanglement local minima, see Sec.~\\\\ref{sec:3}',\n",
       " 'The notion of WBP is practical since it is defined by $k$-body density matrices, being much easier to access on a real NISQ device',\n",
       " 'The fact that the prevention of a WBP is sufficient for avoiding the BP may be understood by the intuition from quantum many-body dynamics and the process of thermalization or scrambling of quantum information',\n",
       " 'In the thermalization process the small subsystems are first to become strongly entangled, as is witnessed by the proximity of their density matrix to the infinite temperature density matrix',\n",
       " 'This intuition suggests that it is enough to keep in check the density matrices of small subsets of qubits',\n",
       " 'If their entanglement or other properties are far away from thermal, the system overall is still far away from the BP.Practically, the WBP can be diagnosed using the shadow tomography scheme~\\\\cite{huang2020predicting}',\n",
       " 'This scheme enables an efficient way of representing a classical snapshot of a quantum wave function on a classical computer',\n",
       " \"In essence, the shadow tomography replaces the measurements performed in the computational basis with a more general measurements, that turns out to be sufficient for reconstructing linear and non-linear function of the state, such as expectation values of few-body observables and second R\\\\'enyi entropy of few-body reduced density matrices respectively\",\n",
       " 'Relying on the shadow tomography, we propose the following modification of the VQE shown by dashed lines in Figure~\\\\ref{fig:1}(b)',\n",
       " \"In essence, we suggest to use the tomography to \\\\emph{simultaneously} measure the cost function value and the $k$-body second R\\\\'enyi entropy\",\n",
       " 'For the derivative we require an additional $2pN$ tomographies (two for each parameter) to compute the gradient exactly using the parameter shift rule~\\\\cite{mitarai2018quantum, schuld2019evaluating}',\n",
       " \"Access to the second R\\\\'enyi entropy allows to prevent the appearance of WBPs not only at the initialization step, but throughout the optimization cycle\",\n",
       " \"The explicit algorithm works as follows:\\\\begin{algorithm}[H]\\\\caption{WBP free optimization with shadows}\\\\label{algo:wbp}\\\\begin{algorithmic}[1]\\\\State Choose $\\\\alpha$, default is $\\\\alpha=1$ \\\\Comment see Sec.~\\\\ref{sec:3a} for details\\\\State Choose $\\\\bm{\\\\theta}$ such that $S_2< \\\\alpha S^{\\\\text{Page}}(k, N)$\\\\State Choose learning rate $\\\\eta$\\\\Repeat \\\\Comment see Appendix~\\\\ref{appx:shadows} for details \\\\State Obtain classical shadows $\\\\hat{\\\\rho}^{(t)} (\\\\bm{\\\\theta})$ \\\\State Use them to compute $E(\\\\bm{\\\\theta})$, $\\\\nabla_{\\\\bm{\\\\theta}}E(\\\\bm{\\\\theta})$ and $S_2 (\\\\bm{\\\\theta})$\\\\If{$S_2< \\\\alpha S^{\\\\text{Page}}(k, N)$}\\\\State $\\\\bm{\\\\theta} \\\\leftarrow \\\\bm{\\\\theta}-\\\\nabla_{\\\\bm{\\\\theta}} E(\\\\bm{\\\\theta})$\\\\Else \\\\State Start again with smaller $\\\\eta \\\\leftarrow \\\\eta'$  \\\\EndIf\\\\Until{convergence of $E(\\\\bm{\\\\theta})$}\\\\end{algorithmic}\\\\end{algorithm}If a WBP is diagnosed at the initialization, one may have to take a different initial value of the variational angles or change the initialization ensemble\",\n",
       " 'These aspects are discussed in details in Sec.~\\\\ref{sec:3}',\n",
       " 'In addition, the WBP can occur in the optimization loop',\n",
       " \"This can be mitigated by keeping track of the second R\\\\'enyi entropies in the optimization process\",\n",
       " 'If the WBP condition is fulfilled, one must restart the algorithm with a smaller learning rate',\n",
       " 'In the Section~\\\\ref{sec:4} we discuss the optimization process in greater details',\n",
       " 'In particular, we will show how the learning rate is related to the potential change in entanglement entropy which implies that a smaller learning rate is generally better at avoiding WBPs',\n",
       " 'As mentioned in the above, BPs for local cost functions are a consequence of the unitary ensemble $\\\\mathcal{E}\\\\sim \\\\{U(\\\\bm{\\\\theta})\\\\}_{\\\\bm{\\\\theta}}$ forming a $2$-design~\\\\cite{mcclean2018barren, cerezo2020cost} which leads to an exponentially vanishing gradient variance, i.e.~a BP',\n",
       " 'What is important to note is that  the exponential decay is simply a witness of the emergence of a $2$-design',\n",
       " \"Another, equivalent witness is the second R\\\\'enyi entropy, where we have:\\\\begin{theorem}{(2-design and R\\\\'enyi entropy)} \\\\label{thm:2-design} \\tIf the unitary ensemble $\\\\mathcal{E}\\\\sim \\\\{ U(\\\\bm{\\\\theta}) \\\\}$ forms a 2-design, then %we have that  \\tfor typical instances the second R\\\\'enyi of the state $\\\\rho_A$ concentrates around the Page value $$S^{\\\\rm{Page}}(k, N) - \\\\frac{1}{2^{N-2k+1}} \\\\leq\\t\\\\mathbb{E}_{\\\\mathcal{E}}\\\\big[ S_2(\\\\rho_A) \\\\big] \\\\leq S^{\\\\rm Page}(k, N),$$ for all subregions $A$ of size $k\\\\ll N$\",\n",
       " '\\\\end{theorem}\\\\noindent These results are known in the literature, and in the context of random quantum circuits, can be found in Refs.~\\\\cite{popescu2006entanglement, oliveira2007, dahlsten2007typicalentanglement}',\n",
       " 'However, for completeness we also provide a proof in Appendix~\\\\ref{app:ent}.The Theorem above implies that large amount of entanglement naturally follows from the similarity between the considered circuit and a random unitary (2-design)',\n",
       " 'Such similarity also gives rise to the vanishing variance of local cost function gradients that define BPs',\n",
       " 'Therefore, so-called entanglement induced BPs~\\\\cite{marrero2020entanglement} and BPs for local cost functions are the same',\n",
       " 'In fact, entanglement provides an intuitive picture for the emergence of BPs and its circuit depth dependence',\n",
       " 'Every entangling layer in the circuit typically increases entanglement of the resulting wave function, until it saturates to its maximal value for any subregion of $k$-qubits at a circuit depth $p\\\\sim \\\\mathcal{O} (\\\\text{poly} (N))$',\n",
       " \"If the second R\\\\'enyi entropy for half of the subsystem $k=N/2$ has saturated, it has saturated for all smaller subsystem sizes and is thus a sufficient check for a BP\",\n",
       " \"Computing the second R\\\\'enyi is however typically exponentially hard in subsystem size on NISQ devices (for single-copy access this was recently proven in Ref.~\\\\cite{chen2021exponential,huang2021learning})\",\n",
       " 'It is therefore only practical to check a small subregion where $k$ is small and independent of system size',\n",
       " ' The above considerations naturally lead us to introduce the notion of WBPs as a modification of the BP that is computationally efficient to diagnose on NISQ devices',\n",
       " 'More formally we have that:\\\\begin{definition}{(Weak barren plateaus)}\\\\label{def:1} \\tLet $H$ be an $N$-qubit Hamiltonian, and $A$ is a region containing $k$ qubits',\n",
       " \"We define a weak barren plateau by the second R\\\\'enyi entropy of the reduced density matrix $\\\\rho_A$ satisfying $S_2 \\\\geq \\\\alpha S^{\\\\text{\\\\rm Page}}(k,N)$ with $\\\\alpha \\\\in [0, 1)$\",\n",
       " ' \\\\end{definition}This definition works for any $k$, however it is reasonable to use $k$ that corresponds to the number of spins involved in interaction terms in the Hamiltonian $H$ since it provides a natural length scale',\n",
       " 'Moreover, in such case the reduced density matrix of subregion with $k$ spins contains all necessary information needed to extract the expectation values of Hamiltonian terms localized inside this region',\n",
       " 'While a WBP is a necessary condition for a BP, it is however not sufficient (which motivates the term \\\\textit{weak})',\n",
       " 'From a practical perspective we are actually only interested in avoiding a BP',\n",
       " 'For this, WBPs provide a powerful tool, since:\\\\begin{corollary}\\\\label{corollary}    If we find a particular subregion $A$ such that $\\\\rho_A$ does not satisfy the weak barren plateau condition, i.e.\\\\ Definition 2, it is on average also not in a barren plateau where the variance is exponentially small.\\\\end{corollary}\\\\begin{proof} This assertion immediately follows from negating Theorem~\\\\ref{thm:2-design}.\\\\end{proof}If the state restricted to the smaller subsystem has not scrambled, then neither has the state restricted to a larger subregion',\n",
       " 'Using classical shadows we can efficiently check all subregions of size $k$ with only a $k \\\\ln(N)$-overhead in the measurement budget, see Appendix~\\\\ref{appx:shadows} for details',\n",
       " 'If any of these subregions avoids the WBP condition, we are guaranteed to also avoid an actual BP',\n",
       " 'This argument is also intuitive to see by considering a causal cone (blue region) that indicates the extent of the so-called scrambled region (i.e',\n",
       " 'extend of a subregion with entropy close to the maximal value) in the circuit, see Fig.~\\\\ref{fig:2} (a)',\n",
       " 'Such scrambled region grows with every consecutive entangling layer $W_l$ (see Eq.~(\\\\ref{eq:ruc}))',\n",
       " 'When this region extends beyond $k$ qubits, the WBP is reached (left orange dashed line)',\n",
       " \"Later, when the ``scrambling lightcone'' has extended to the full system, the BP is reached (right orange dashed line)\",\n",
       " 'Once the BP is reached all smaller regions are also fully entangled and will satisfy the WBP condition on average.\\\\begin{figure}[tb]    \\\\centering    \\\\includegraphics[width=0.98\\\\columnwidth]{figures/fig2.pdf}    \\\\caption{Sketch of the circuit, where the blue color shows the scrambling lightcone',\n",
       " 'The lightcone first extends over $k$ qubits, where the WBP occurs, and for larger circuit depths extends to the full system size where the BP occurs',\n",
       " \"(b) The saturation of the gradient variance $\\\\text{Var}[\\\\partial_{1,1} E]$ and (c) saturation of the bipartite second R\\\\'enyi entropy $S_2(\\\\rho_A)$ of the region $A$ consisting of qubits $1,\\\\ldots, N/2$ nearly to the Page value happen at the similar circuit depths $p$, that increases with the system size $N$\",\n",
       " \"(d) In contrast, the saturation of the second R\\\\'enyi for two qubits ($A'=\\\\{1,2\\\\}$) is system size independent, illustrating that WBP precedes the onset of a BP\",\n",
       " 'Data was averaged over $100$ random initializations',\n",
       " 'Gradient variance is computed for the local term $\\\\sigma_1^z \\\\sigma^z_2$, typically used in BP illustrations',\n",
       " 'Gradient variance for the full Heisenberg Hamiltonian, Eq.~(\\\\ref{eq:heisenberg}), looks similar.}    \\\\label{fig:2}\\\\end{figure}Fig.~\\\\ref{fig:2} provides a numerical illustration for the Corollary~\\\\ref{corollary} stated above',\n",
       " \"We use the hardware-efficient circuit, presented in Eq.~(\\\\ref{eq:ruc}), and compute the gradient variance and second R\\\\'enyi entropy as a function of circuit depth $p$ for different system sizes $N$\",\n",
       " 'We fix $\\\\ket{\\\\psi_0} = \\\\ket{0}$ as the initial state, which is simply all qubits in the zero state',\n",
       " 'Panel (b) shows the exponential decay of the gradient variance that is usually used to diagnose a BP',\n",
       " \"Panel (c) shows the corresponding bipartite second R\\\\'enyi entropy\",\n",
       " 'We see that it indeed approaches the Page value (gray dashed line)',\n",
       " \"The Page value is not fully reached since we are considering the second R\\\\'enyi instead of the von Neumann entanglement entropy, this difference however becomes negligible once the subsystem size is decreased\",\n",
       " \"This numerically illustrates that when the $2$-design is reached both the gradient variance and bipartite second R\\\\'enyi entropy have converged\",\n",
       " \"In panel (d) we consider a smaller region of two qubits and see that the second R\\\\'enyi for this region saturates to its maximal value at a significantly lower circuit depth\",\n",
       " 'This illustrates the emergence of the WBP that precedes the onset of the BP after a few more entangling layers',\n",
       " 'Before the WBP is reached, gradients are well behaved and do not decrease exponentially with the system size',\n",
       " 'Finally, we address the effects of the control parameter $\\\\alpha$, that enters in Definition~\\\\ref{def:1} of the WBP',\n",
       " 'The naive choice is $\\\\alpha=1$ which means that a WBP is reached if the subregion is maximally entangled with the rest of the system',\n",
       " 'However, in the case when some a priori knowledge about the entanglement properties of the target state $\\\\ket{GS}$ is available, it can be used to set a smaller value of $\\\\alpha$',\n",
       " 'If, for instance, the ground state is only weakly entangled, a choice of $\\\\alpha \\\\ll 1$ may be appropriate',\n",
       " 'In this way Algorithm~1 in Sec.~\\\\ref{sec:wbp_algo} can also help in avoiding convergence to highly entangled local minima',\n",
       " 'We discuss this in more detail in Sec.~\\\\ref{sec:4b}',\n",
       " ' ',\n",
       " 'In order to illustrate the notion of WBP in a more specific setting we apply it to the initialization process of the VQE',\n",
       " 'Specifically, we focus on the family of initializations that was proposed earlier in order to avoid the issue of BPs~\\\\cite{holmes2021connecting, haug2021capacity}',\n",
       " 'The one-parametric family of initializations restricts the single qubit rotation angles from ansatz Eq.~(\\\\ref{eq:ruc}) as $\\\\theta_l^i \\\\in \\\\epsilon_{{\\\\theta}} [-\\\\pi, \\\\pi)$, where  $\\\\epsilon_{{\\\\theta}} \\\\in [0, 1)$ is the control parameter',\n",
       " 'This strategy allows to delay the onset of BP to arbitrary circuit depths by tuning $\\\\epsilon_{{\\\\theta}}$ accordingly',\n",
       " 'Similarly, it allows to delay the onset of WBPs',\n",
       " 'Depending on the parameter $\\\\epsilon_{{\\\\theta}}$ one can afford a deeper circuit without encountering a WPB in the initialization when compared to the full parameter range ($\\\\epsilon_{{\\\\theta}}=1$)',\n",
       " 'It is straightforward to see that for $\\\\epsilon_{{\\\\theta}}=0$, the ansatz is WBP-free for all circuit depths',\n",
       " 'Indeed, in absence of the single qubit rotations, the entangling gates in $W_l$ do not create any entanglement (since the CZ gates used in Eq.~(\\\\ref{eq:ruc}) are diagonal in the computational basis), leaving $\\\\ket{0}$ invariant',\n",
       " \"Note that, for example, the \\\\textit{identity block} initialization, proposed by \\\\citeauthor{grant2019initialization} works in a similar way in that the unitary is constructed such that it also implements the identity and one is equally left with the zero state.\\\\begin{figure}[tb]    \\\\centering    \\\\includegraphics[width=\\\\columnwidth]{figures/fig3.pdf}    \\\\caption{(a) Decreasing parameter $\\\\epsilon_{{\\\\theta}}$ from 1 slows down the growth of the second R\\\\'enyi entropy with the circuit depth $p$\",\n",
       " 'The chosen region contains two qubits',\n",
       " ' (b) The encounter of BP in the variance of the gradient of the cost function is visible only for the case $\\\\epsilon_\\\\theta=1$, and it is preceded by the onset of WBP',\n",
       " 'We use a system size of $N=16$ for (a) and $N=8, \\\\cdots, 16$ for (b), color intensity corresponds to system size, same as in Fig.~\\\\ref{fig:2}',\n",
       " \"Data is averaged over $100$ random instances, variance is for the local term $\\\\sigma_1^z \\\\sigma_2^z$.}    \\\\label{fig:3}\\\\end{figure}In Fig.~\\\\ref{fig:3} we numerically illustrate the influence of $\\\\epsilon_{{\\\\theta}}$ on the growth of entanglement and its relation to the gradient variance.Panel (a) illustrates the growth of the second R\\\\'enyi entropy in the circuit for three different small angle parameters $\\\\epsilon_{{\\\\theta}}$ and panel (b) shows the corresponding gradient variance\",\n",
       " 'Outside of the WBP the gradient variance vanishes only polynomially',\n",
       " 'This illustrates that the avoidance of a WBP is sufficient for avoiding a BP and thus allows for a simple strategy for constructing BP-free initializations',\n",
       " 'In Sec.~\\\\ref{sec:2} we presented how the general VQE can be extended with minimal overhead to avoid WBPs in the optimization procedure',\n",
       " 'The learning rate, as presented in Algorithm 1, hereby plays a crucial role',\n",
       " 'A smaller learning rate, as observed in Fig.~\\\\ref{fig:1} (c)-(e) is more likely to avoid a WBP',\n",
       " 'To understand this phenomenological observation on more rigorous grounds, let us consider a sufficiently deep circuit (with a polynomial number of layers in system size), so that the optimization landscape is dominated by WBPs',\n",
       " 'Careful selection of the parameters allows for an initialization outside of a WBP',\n",
       " 'However, to remain in the WBP-free region, the optimization has to be performed in a controlled manner, such that the optimizer does not leave the region of low entanglement due to large learning rate and does not end in a WBP',\n",
       " \"Since WBPs are defined in terms of the second R\\\\'enyi entropy $S_2$, we need to bound the change in $S_2$ between iteration steps $t$ and $t+1$\",\n",
       " 'For practical purposes, we instead use the purity ($\\\\tr \\\\rho^2_A = e^{-S_2}$)',\n",
       " 'The change in purity is upper bounded by~\\\\cite{renyis_continuitybound}\\\\begin{equation}\\\\label{eq:renyis_continuitybound}  \\\\left|\\\\tr \\\\rho^2_A(t+1) - \\\\tr \\\\rho^2_A(t)\\\\right| \\\\leq 1-(1-T_A(t))^2- \\\\frac{T^2_A(t)}{2^k-1},  \\\\end{equation}where $T_A(t) \\\\equiv T(\\\\rho_A(t), \\\\rho_{A}(t+1))$ is the trace distance between the reduced density matrices at iteration steps $t$ and $t+1$, and we assume that region $A$ has $k$ qubits',\n",
       " 'Assuming that the states at consecutive updates steps of gradient descent are pertubatively close (see Appendix~\\\\ref{appx:perturb_learning} for details), as measured by the trace distance, one can show that\\\\begin{equation}\\\\label{eq:trace_learning}\\tT(\\\\rho_A(t+1), \\\\rho_A(t)) \\\\lesssim \\\\sqrt{\\\\frac{\\\\eta^2}{4} (\\\\nabla_{\\\\bm{\\\\theta}}E)^T \\\\mathcal{F}(\\\\bm{\\\\theta}) \\\\nabla_{\\\\bm{\\\\theta}}E},\\\\end{equation}where $\\\\mathcal{F}_{i,j}(\\\\bm{\\\\theta})=4\\\\mathop{\\\\rm{Re}}[\\\\langle \\\\partial_i \\\\psi| \\\\partial_j \\\\psi \\\\rangle-\\\\langle \\\\partial_i \\\\psi|\\\\psi\\\\rangle \\\\langle \\\\psi| \\\\partial_j \\\\psi \\\\rangle]$ is the quantum Fisher information matrix (QFIM)~\\\\cite{meyer2021fisher} and $\\\\eta$ is the learning rate',\n",
       " 'Inequalities~\\\\eqref{eq:renyis_continuitybound}-\\\\eqref{eq:trace_learning} imply that the learning rate $\\\\eta$ can be used to limit the maximal possible change of the purity.\\\\footnote{A similar continuity bound which does not require the QFIM can be found in terms of the maximum operator norm of the gate generators',\n",
       " \"We acknowledge Johannes Jakob Meyer for this remark.} Provided that the change in purity is sufficiently small, the Taylor expansion can be used to argue that the corresponding change in the second R\\\\'enyi entropy $S_2$, related to the purity as $e^{-S_2} = \\\\tr \\\\rho_A^2$, also remains controlled\",\n",
       " 'Therefore, the choice of an appropriately small learning rate can guarantee the avoidance of a WBP at $t+1$, provided the absence of one at $t$.\\\\begin{figure}[t]    \\\\centering    \\\\includegraphics[width=\\\\columnwidth]{figures/fig4.pdf}    \\\\caption{(c) We numerically illustrate the continuity bound Eq.~(\\\\ref{eq:renyis_continuitybound}) and its relation to the learning rate $\\\\eta$ for $t=0$, i.e',\n",
       " 'at the beginning of the optimization schedule',\n",
       " 'This shows that one should be careful with the choice of the learning rate since a large learning rate leads to a big change in the trace distance and change in purity',\n",
       " 'We use a system size of $N=10$ and a random circuit with circuit depth $p=100$ and small qubit rotations ($\\\\epsilon_\\\\theta=0.05$) to generate a BP-free initialization',\n",
       " 'Data was averaged over $500$ random instances.}    \\\\label{fig:4}\\\\end{figure}To illustrate the bound numerically, we prepare an initialization outside of the  WBP using a small angle parameter $\\\\epsilon_{\\\\bm{\\\\theta}}$ and compute the change in the purity $\\\\tr \\\\rho_A^2$ after one GD update step for different learning rates $\\\\eta$',\n",
       " 'The results of this procedure for four different learning rates are shown in Fig.~\\\\ref{fig:4}',\n",
       " 'We see that larger learning rates correspond to a bigger change in purity and are thus more prone to encounter a WBP',\n",
       " 'At the same time, all data points are below the theoretical bound',\n",
       " '% (solid line) that corresponds to the right hand side of inequality~(\\\\ref{eq:renyis_continuitybound})',\n",
       " 'While up to the best of our knowledge the bound Eq.~(\\\\ref{eq:renyis_continuitybound}) is not proven to be tight, we observe that points corresponding to the extreme learning rates closely approach the theoretical line.Using Eq.~\\\\eqref{eq:trace_learning}, the bound can be efficiently approximated on NISQ hardware: the QFIM can be estimated efficiently on a quantum device using techniques suggested in Ref.~\\\\cite{gacon2021simultaneous} or Ref.~\\\\cite{rath2021quantum} using classical shadows',\n",
       " 'For the computation of the gradient one can use the parameter shift rule~\\\\cite{mitarai2018quantum, schuld2019evaluating} also with shadow tomography',\n",
       " 'The expression can thus be efficiently evaluated on a real device and used together with the continuity bound to estimate a suitable learning rate $\\\\eta$',\n",
       " 'However, in practice this might not be needed and simply following Algorithm 1 could be more efficient and easier to implement',\n",
       " 'Finally, we illustrate Algorithm 1 in practice',\n",
       " 'To this end we first prepare a WBP-free initial state using small qubit rotation angles and compare the performance of GD optimization with different learning rates',\n",
       " ' If we start with a large learning rate, $\\\\eta=1$, corresponding to red lines in Fig.~\\\\ref{fig:1}~(c)-(e), we see that the energy expectation value in Fig.~\\\\ref{fig:1}~(c) rapidly (within one or two update steps) converges to a value far away from the target ground state energy $E_{\\\\text{GS}}$',\n",
       " \"At the same time, panel (d) reveals that this can be attributed to an onset of a WBP, as the second R\\\\'enyi entropy spikes up to the Page value\",\n",
       " 'Finally, panel (e) shows that the gradient norm also is convergent, though at non-zero value',\n",
       " 'We attribute this to the fact that the system gets trapped in the WBP region',\n",
       " 'As suggested by Algorithm 1, we thus decrease the learning rate to $\\\\eta=0.1$ and start again',\n",
       " 'This time a WBP is avoided, the algorithm however gets stuck in a local minimum with large entanglement entropy',\n",
       " 'In this instance a choice of parameter $\\\\alpha$ that defines an onset of a WBP in Def.~\\\\ref{def:1} being smaller than one may be beneficial',\n",
       " 'For instance, setting $\\\\alpha=0.5$ could help avoiding the suboptimal local minima characterized by large entanglement, see grey dashed line in Fig.~\\\\ref{fig:1} (d)',\n",
       " 'Note that the large gradient persistent after many iterations for blue line in Fig.~\\\\ref{fig:1}(e) may also indicate that the learning rate is chosen too large for the width of the local minima.Provided that our algorithm uses $\\\\alpha=0.5$, the system would satisfy a WBP condition even for learning rate $\\\\eta=0.1$, forcing us to restart algorithm with even smaller learning rate',\n",
       " 'Setting $\\\\eta=0.01$, we see that the algorithm is now able to converge very close to the true ground state energy (violet line in Fig.~\\\\ref{fig:1}~(c)-(e))',\n",
       " 'In particular, the norm of the gradient assumes the smallest value among all learning rates',\n",
       " 'We note, that the further decrease of the learning rate (i.e.\\\\ to $\\\\eta=0.001$) degrades the performance of GD',\n",
       " 'While WBPs are not encountered during the optimization  process, the GD optimization converges slower and within the given iterations to a larger energy expectation value',\n",
       " 'This highlights the fact that it is best to choose the highest possible learning rate, that still avoids a WBP',\n",
       " 'We speculate, that an optimization strategy that adapts the learning rate at each optimization step would give the best performance, though testing this assumption is beyond the scope of the present work',\n",
       " '   Finally, let us comment on the usage of shadows in the process of optimization',\n",
       " 'The shadow tomography provides an efficient way for diagnosing when system enters a WBP region',\n",
       " 'In principle, shadows may also provide a more efficient way of measuring the cost function',\n",
       " 'However, for the Heisenberg Hamiltonian, Eq.~(\\\\ref{eq:heisenberg}), used in this work, the shadow protocol does not offer a speed-up for the estimation of the energy expectation value, see Appendix~\\\\ref{appx:shadows} for a detailed discussion.',\n",
       " 'The main result of this work is the introduction of the concept of WBPs, which in essence provide an efficiently detectable version of BPs',\n",
       " \"In particular, we propose to use the classical shadows protocol to estimate the second R\\\\'enyi entropy of a small subregions that are independent of system size\",\n",
       " 'If these subregions avoid nearly maximal entanglement -- a condition sufficient for avoiding WBPs -- the system also avoids conventional BPs',\n",
       " 'Building on this definition of the WBP, we proposed an algorithm that is capable of avoiding BPs on NISQ devices without requiring a computational overhead that scales exponentially in system size',\n",
       " 'In order to illustrate the notion of WBPs and the proposed algorithm, we studied a particular BP-free initialization of the variational quantum eigensolver',\n",
       " 'Furthermore, we considered an optimization procedure that uses gradient descent',\n",
       " 'Phenomenologically, we observed that the encounter of a BP during the optimization crucially depends on the learning rate, which controls the parameter update magnitude between consecutive optimization steps',\n",
       " 'A smaller learning rate is less likely to lead to the encounter of a BP during the optimization',\n",
       " 'However, choosing the learning rate to be very small degrades the performance of GD',\n",
       " 'These results support the feasibility of the proposed algorithm for efficiently avoiding BPs on NISQ devices',\n",
       " 'While our results and numerical simulations are focused on variational quantum eigensolvers (VQE), they readily extend to other variational hybrid algorithms, such as quantum machine learning~\\\\cite{benedetti2019parameterized, havlicek2019supervised, schuld2020circuit-centric}, quantum optimization~\\\\cite{farhi2014quantum, sack2021quantumannealing, harrigan2021quantum} or variational time evolution~\\\\cite{barison2021efficientquantum, lin2021real}',\n",
       " 'Although the issue of avoiding BPs at the circuit initialization is a subject of active research~\\\\cite{grant2019initialization, dborin2021matrix, skolik2020layerwise, holmes2021connecting}, the influence and role of BPs in the optimization process has received much less attention',\n",
       " 'Our results indicate that entanglement, in addition to playing a crucial role for circumventing BPs at the launch of the VQE, is also important for achieving a good optimization performance',\n",
       " 'In addition, our heuristic results in Sec.~\\\\ref{sec:4} suggest that post-selection based on the entanglement of small subregions may help to avoid low-quality local minima that are characterized by higher entanglement',\n",
       " 'Algorithm~1 allows for such post-selection by appropriately tuning the value of $\\\\alpha$',\n",
       " 'Doing so, however, requires some prior knowledge about the entanglement structure of the target state',\n",
       " 'This may be inferred from the structure of the Hamiltonian (for instance, for a Hamiltonian that is diagonal in the computational basis, the eigenstates are product states with no entanglement), or by targeting small instances of the computational problem using exact diagonalization.Beyond that, one could imagine an algorithm where the learning rate is not only adapted when a WBP is encountered, but dynamically adjusted at every step of the optimization process',\n",
       " 'This may allow for efficiently maneuvering complicated optimization landscapes by staying clear of highly entangled local minima',\n",
       " 'VQE, for instance, is known to have many local minima~\\\\cite{bittel2021training}, but a systematic study of their entanglement structure, required for devising such dynamic entanglement post-selection procedure, has yet to be done.Another important question concerns the effect of noise, which has been suggested to be an additional source for the emergence of BPs~\\\\cite{wang2020noise}',\n",
       " 'Noise cannot be avoided on NISQ machines and has a profound impact on any near-term quantum algorithm which is difficult to analyze analytically',\n",
       " 'Fortunately, none of the tools we propose are especially susceptible to noise corruption.In fact, both the classical shadow protocol and the estimation of observables and purities are stable with respect to the addition of a small but finite amount of noise, and there have even been some proposals for noise mitigation techniques~\\\\cite{chen2021robust,koh2020classical}',\n",
       " 'Finally, we comment on the possibility of testing Algorithm~1 on a real NISQ device',\n",
       " 'While the shadows protocol can readily be implemented on near-term devices to diagnose WBPs, whether a variational circuit with enough entangling layers that lead to a BP can be realized on a NISQ device is not entirely clear at this stage',\n",
       " 'Nevertheless recent results of Ref.~\\\\cite{mi2021information} observed convergence of the out-of-time correlators to zero, indicating that a 2-design might already have been reached',\n",
       " 'This implies that large entanglement, as present in a BP, could be realizable on available NISQ devices, and opens the door to experimental studies of the effect of entanglement on the optimization performance on current NISQ machines using the proposed shadows protocol',\n",
       " ' ',\n",
       " 'We thank Marco Cerezo, Zoe Holmes, and Nicholas Hunter-Jones for fruitful discussion and valuable feedback',\n",
       " 'We also acknowledge Adam Smith, Johannes Jakob Meyer, and Victor V',\n",
       " 'Albert for comments on the manuscript',\n",
       " 'The simulations were performed in the Julia programming language~\\\\cite{julia} using the Yao module~\\\\cite{yao}',\n",
       " 'S.H.S., R.A.M., and M.S',\n",
       " \"acknowledge support by the European Research Council (ERC) under the European Union's Horizon 2020 research and innovation program (Grant Agreement No.~850899).\",\n",
       " '\\\\appendix',\n",
       " '\\\\emph{Shadow tomography} attempts to directly estimate interesting properties of an unknown state without performing full state tomography as an intermediate step',\n",
       " '\\\\citeauthor{aaronson2018shadow} and \\\\citeauthor{aaronson2019gentle} showcased that such a direct estimation protocol can be exponentially more efficient, both in terms of Hilbert space dimension ($2^N$ in our case) and in the number of target properties (we will use $L$ to denote this cardinality)',\n",
       " 'These techniques do, however, require to store copies of the underlying quantum state in parallel within a quantum memory and performing highly entangled gates on all copies simultaneously',\n",
       " 'This is too demanding for current and near-term quantum devices',\n",
       " '\\\\citeauthor{huang2020predicting} developed a more near-term friendly variant of this general idea known as prediction with \\\\emph{classical shadows}',\n",
       " 'Similar ideas have been independently proposed by  \\\\citeauthor{paini2019approximate} and \\\\citeauthor{morris2019selective}, respectively',\n",
       " 'As explained in detail below, the key idea is to sequentially generate state copies and perform randomly selected single-qubit Pauli measurements',\n",
       " 'Such measurements can be routinely implemented in current quantum hardware and enable the prediction of many (linear and polynomial) properties of the underlying quantum state',\n",
       " 'Importantly, the measurement budget (number of required measurements) still scales logarithmically in the number of target properties $L$, but it may scale exponentially in the support size $k$ of these properties',\n",
       " 'This is not a problem for local features, like subsystem purities or terms in a quantum many-body Hamiltonian, but does prevent us from directly estimating global state features like fidelity estimation',\n",
       " 'We use randomized single-qubit measurements to extract information about a variational $N$-qubit state represented by a density matrix\\\\begin{equation*}\\\\rho (\\\\bm{\\\\theta}) = |\\\\psi (\\\\bm{\\\\theta}) \\\\rangle \\\\! \\\\langle \\\\psi (\\\\bm{\\\\theta})| \\\\quad \\\\text{with $\\\\bm{\\\\theta} \\\\in \\\\mathbb{R}^m$.}\\\\end{equation*}To this end, we repeat the following procedure a total of $T$ times',\n",
       " 'For $1 \\\\leq t \\\\leq T$ we\\\\begin{enumerate}    \\\\item Prepare quantum state $\\\\rho (\\\\bm{\\\\theta})$ on the NISQ device',\n",
       " '   \\\\item Select $N$ single-qubit Pauli observables independently and uniformly at random',\n",
       " \"   \\\\item Perform the associated $N$-qubit Pauli measurement (single-shot) to obtain $N$ classical bits ($0$ if we measure `spin down' and $1$ if we measure `spin up')\",\n",
       " \"   \\\\item Store $N$ single-qubit `post-measurement' states, $|s_i^{(t)}\\\\rangle$, where an $i$-th qubit measurement outcome, $s_i$, can take six possible values denoted as $|0 \\\\rangle$, $|1 \\\\rangle$ if qubit was measured in $z$-basis, $|+ \\\\rangle$ and $|- \\\\rangle$ for $x$-basis, and, finally, $| +\\\\mathrm{i}\\\\rangle$ and $|-\\\\mathrm{i}\\\\rangle$ for $y$-basis\",\n",
       " 'Here, $|\\\\pm \\\\rangle = \\\\left( |0 \\\\rangle \\\\pm |1 \\\\rangle \\\\right)/\\\\sqrt{2}$ denote Pauli-$x$ matrix eigenstates and $|\\\\pm \\\\mathrm{i} \\\\rangle = \\\\left(|0 \\\\rangle \\\\pm \\\\mathrm{i}|1\\\\rangle \\\\right)/\\\\sqrt{2}$ are two Pauli-$y$ eigenstates',\n",
       " 'In practice, this is achieved by applying random single qubit Clifford gates that effectively implement a change of basis such that the usual $z$-basis measurement can be used, see Fig.~\\\\ref{fig:1} (a) for a visualization',\n",
       " '   \\\\item (Implicitly) construct the $N$-qubit \\\\emph{classical shadow}    \\\\begin{equation}    \\\\hat{\\\\rho}^{(t)} (\\\\bm{\\\\theta}) =      \\\\bigotimes_{i=1}^N \\\\left( 3 |s_i^{(t)} \\\\rangle \\\\! \\\\langle s_i^{(t)}|- \\\\mathbb{I} \\\\right)',\n",
       " '\\\\label{eq:shadow}    \\\\end{equation}\\\\end{enumerate}Repeating this procedure a total of $T$ times provides us with $T$ classical shadows $\\\\rho^{(1)} (\\\\bm{\\\\theta}),\\\\ldots,\\\\rho^{(T)} (\\\\bm{\\\\theta})$.These are random matrices that are statistically independent (because they are constructed from independent quantum measurements).By construction, each classical shadow reproduces the true underlying state in expectation (over both the choice of Pauli observable and the observed spin direction):\\\\begin{equation}\\\\mathbb{E} \\\\left[ \\\\hat{\\\\rho}^{(t)} (\\\\bm{\\\\theta}) \\\\right]= \\\\rho (\\\\bm{\\\\theta}) = |\\\\psi (\\\\bm{\\\\theta}) \\\\rangle \\\\! \\\\langle \\\\psi (\\\\bm{\\\\theta})|, \\\\label{eq:shadow-average}\\\\end{equation}see e.g.\\\\ Ref.~\\\\cite[Proposition~S.2]{huang2020predicting}.We can now approximate this ideal expectation value by empirical averaging over all samples:\\\\begin{equation*}\\\\rho (\\\\bm{\\\\theta}) \\\\approx \\\\frac{1}{T}\\\\sum_{t=1}^T \\\\hat{\\\\rho}^{(t)} (\\\\bm{\\\\theta}).\\\\end{equation*}This approximation becomes exact in the limit $T \\\\to \\\\infty$ of infinitely many measurement repetitions',\n",
       " 'But the main results in Refs.~\\\\cite{huang_2020,paini2019approximate} highlight that convergence actually happens much more rapidly',\n",
       " 'This is, in particular, true for subsystem density matrices',\n",
       " 'The tensor product structure of classical shadows~\\\\eqref{eq:shadow} plays nicely with taking partial traces.Let $A \\\\subseteq \\\\left\\\\{1,\\\\ldots,N\\\\right\\\\}$ be a collection of $|A|=k$ qubits',\n",
       " 'Then,\\\\begin{equation}\\\\hat{\\\\rho}_A^{(t)}(\\\\bm{\\\\theta}) = \\\\mathrm{tr}_{\\\\neg A} \\\\left( \\\\hat{\\\\rho}_A^{(t)}\\\\right)  \\\\label{eq:reduced-shadow}\\\\end{equation}is a $k$-qubit shadow that can be used to approximate the associated subsystem density matrix',\n",
       " 'More precisely, Eq.~\\\\eqref{eq:shadow-average} asserts\\\\begin{equation}\\\\mathbb{E} \\\\left[ \\\\rho_A^{(t)}(\\\\bm{\\\\theta})\\\\right] = \\\\mathrm{tr}_{\\\\neg A}\\\\left( \\\\mathbb{E} \\\\left[ \\\\hat{\\\\rho}^{(t)}(\\\\bm{\\\\theta}) \\\\right]\\\\right) = \\\\mathrm{tr}_{\\\\neg A}(\\\\rho(\\\\bm{\\\\theta})) = \\\\rho_A (\\\\bm{\\\\theta})\\\\label{eq:reduced-average}\\\\end{equation}which can (and should) form the basis of empirical averaging directly for the subsystem in question',\n",
       " 'Here is a mathematically rigorous result in this direction',\n",
       " 'In what follows, the range (or weight) of an observable is the number of qubits on which it acts nontrivially',\n",
       " 'E.g.\\\\ coupling terms in the Heisenberg Hamiltonian~\\\\eqref{eq:heisenberg} have range $k=2$, while the external field terms have range $k=1$.\\\\begin{theorem} \\\\label{thm:linear-shadows}Fix a collection of $L$ range-$k$ observables $O_l$, as well as parameters $\\\\epsilon,\\\\delta >0$',\n",
       " 'Then, with probability (at least) $1-\\\\delta$, classical shadows of size\\\\begin{equation*}T \\\\geq \\\\frac{4^{k+1} \\\\ln (2L/\\\\delta)}{\\\\epsilon^2}\\\\end{equation*}suffice to jointly estimate \\\\emph{all} $L$ expectation values up to additive accuracy $\\\\epsilon$',\n",
       " 'I.e',\n",
       " '\\\\begin{equation*}\\\\hat{\\\\rho}(\\\\bm{\\\\theta}) = \\\\frac{1}{T}\\\\sum_{t=1}^T \\\\hat{\\\\rho}^{(t)} (\\\\bm{\\\\theta}) \\\\;\\\\text{obeys} \\\\; \\\\left| \\\\mathrm{tr} \\\\left( O_l \\\\hat{\\\\rho}(\\\\bm{\\\\theta})\\\\right) - \\\\mathrm{tr} \\\\left( O_l \\\\rho (\\\\bm{\\\\theta})\\\\right) \\\\right| \\\\leq \\\\epsilon,\\\\end{equation*}for all $1 \\\\leq l \\\\leq L$.\\\\end{theorem}We emphasize that it is not necessary to form global shadow approximations',\n",
       " 'If $O_l$ only acts non-trivially on subsystem $A_l \\\\subseteq \\\\left\\\\{1,\\\\ldots,N\\\\right\\\\}$ ($O_l = \\\\tilde{O}_l \\\\otimes \\\\mathbb{I}_{\\\\neg A_l}$), then $\\\\mathrm{tr} \\\\left( O_l \\\\hat{\\\\rho}(\\\\bm{\\\\theta})\\\\right) = \\\\mathrm{tr} \\\\left( \\\\hat{O}_l \\\\hat{\\\\rho}_{A_l} \\\\right)$.Theorem~\\\\ref{thm:linear-shadows} is slightly stronger than a related result in \\\\cite{huang2020predicting} (it does not require median-of-means estimation).Conceptually similar results have been established in Refs.~\\\\cite{huang2021provably} and \\\\cite{evans2019scalable,huang2021derandomization}, but we are not aware of a formal statement in the form of Theorem~\\\\ref{thm:linear-shadows}',\n",
       " 'We present a formal proof in Appendix~\\\\ref{Sec:proof} below.',\n",
       " \"Suppose we are interested of estimating a collection of multiple subsystem purities\\\\begin{equation}p_A (\\\\bm{\\\\theta}) = \\\\mathrm{tr} \\\\left( \\\\rho_A (\\\\bm{\\\\theta})^2 \\\\right) = \\\\mathrm{tr} \\\\left( \\\\rho_A (\\\\bm{\\\\theta}) \\\\rho_A (\\\\bm{\\\\theta}) \\\\right), %\\\\label{eq:purity-estimate}\\\\end{equation}where $A \\\\subseteq \\\\left\\\\{1,\\\\ldots,N\\\\right\\\\}$ labels different subsystems of size $|A|=k$ each.Then, we can use the corresponding subsystem shadows~\\\\eqref{eq:reduced-shadow} to approximate each $p_A$ by empirical averaging:\\\\begin{align}\\\\hat{p}_A (\\\\bm{\\\\theta}) = \\\\frac{1}{T(T-1)} \\\\sum_{t \\\\neq t'} \\\\mathrm{tr} \\\\left( \\\\hat{\\\\rho}_A^t \\\\hat{\\\\rho}_A^{t'} \\\\right)\",\n",
       " \"\\\\label{eq:purity-estimate}\\\\end{align}It is important that we restrict our averaging operation to distinct pairs of classical shadows ($t \\\\neq t'$).This guarantees that the expectation values factorize, i.e.\\\\ \\\\begin{equation*}\\\\mathbb{E} \\\\left[ \\\\hat{\\\\rho}_A^t \\\\hat{\\\\rho}_A^{t'} \\\\right]= \\\\mathbb{E} \\\\left[ \\\\hat{\\\\rho}_A^t \\\\right] \\\\mathbb{E} \\\\left[ \\\\hat{\\\\rho}_A^{t'} \\\\right] = \\\\rho_A^2,\\\\end{equation*}where the last equality is due to Eq.~\\\\eqref{eq:reduced-shadow}\",\n",
       " 'Formula~\\\\eqref{eq:purity-estimate} is an empirical average over all distinct shadow pairs contained in the data set',\n",
       " 'It converges to the true average $p_A (\\\\bm{\\\\theta})=\\\\mathbb{E} \\\\left[ \\\\hat{p}_A (\\\\bm{\\\\theta}) \\\\right]$, and the speed of convergence is governed by the variance',\n",
       " \"As data size $T$ increases, this variance decays as\\\\begin{equation*}\\\\mathrm{Var} \\\\left[ \\\\hat{p}_A (\\\\bm{\\\\theta}) \\\\right]\\\\leq \\\\frac{2}{T}\\\\left( 2 \\\\times 4^{k} p_2 (\\\\bm{\\\\theta}) + \\\\frac{1}{T-1} 2^{4k}\\\\right),\\\\end{equation*}see e.g.\\\\ Ref.~\\\\cite[SM Eq.~(12)]{neven2021symmetry}.In the large-$T$ limit, this expression is dominated by the first term in parentheses, $4 \\\\times 2^{k}p_2 (\\\\bm{\\\\theta})/T$, and Chebyshev's inequality allows us to bound the probability of a large approximation error\",\n",
       " 'For $\\\\epsilon >0$,\\\\begin{equation*}\\\\mathrm{Pr} \\\\left[ \\\\left| \\\\hat{p}_A (\\\\bm{\\\\theta})-\\\\mathrm{tr} \\\\left( \\\\rho_A (\\\\bm{\\\\theta})^2 \\\\right)\\\\right| \\\\geq \\\\epsilon \\\\right] \\\\lesssim  \\\\frac{4^{k+1} \\\\mathrm{tr} \\\\left( \\\\rho_A^2 \\\\right)}{T \\\\epsilon^2},\\\\end{equation*}provided that the total number of measurements $T$ is large enough to suppress the higher-order contribution in the variance bound (this is why we write $\\\\lesssim$)',\n",
       " 'In this regime, a measurement budget that scales as\\\\begin{equation}T \\\\geq  \\\\frac{4^{k+1} \\\\mathrm{tr} \\\\left( \\\\rho_A^2 \\\\right)}{\\\\epsilon^2 \\\\delta} \\\\label{eq:sample-complexity-purity}\\\\end{equation}suppresses the probability of a sizable approximation error ($\\\\geq \\\\epsilon$) below $\\\\delta$.It is worthwhile to point out that this bound depends on the subsystem purity under consideration',\n",
       " 'Smaller purities are cheaper to estimate than large ones',\n",
       " 'It is also important to note that the accuracy parameter $\\\\epsilon$ has to be small enough in order to accurately capture the purity in the WBP regime, which decays exponentially fast, but only with the subsystem size $k$',\n",
       " ' The $\\\\delta$-dependence in Eq.~\\\\eqref{eq:sample-complexity-purity} can be further improved to $\\\\ln (1/\\\\delta)$ by replacing simple empirical averaging in Eq.~\\\\eqref{eq:purity-estimate} by median-of-means estimation~\\\\cite{huang2020predicting}',\n",
       " 'Doing so would allow us to estimate all possible $L=\\\\binom{N}{k}\\\\leq N^k$ size-$k$ subsystem purities with only a $k \\\\ln(N)$-overhead',\n",
       " 'Median-of-means estimation does, however, worsen the dependence on $\\\\epsilon$ by a constant amount',\n",
       " 'Empirical studies conducted in Ref.~\\\\cite{elben2020mixed} showcase that such a tradeoff only becomes viable if one wishes to approximate polynomially many subsystem purities.',\n",
       " 'To perform the GD update step suggested in Algorithm 1 we require the knowledge of gradient $\\\\nabla_{\\\\bm{\\\\theta}}E(\\\\bm{\\\\theta})$ which consists of $p N$ derivatives $\\\\partial_{i, l}E(\\\\bm{\\\\theta})$',\n",
       " 'The derivative can naively be approximated using finite difference, though for variational single qubit rotation gates, as used in the main text [see Eq.~(\\\\ref{eq:ruc})], we can use the parameter-shift rule to compute the gradients exactly (up to finite sampling errors)~\\\\cite{mitarai2018quantum, schuld2019evaluating}',\n",
       " 'The parameter-shift rule is given by\\\\begin{align*}\\\\partial_{i,l} E \\\\left(\\\\bm{\\\\theta} \\\\right) = \\\\frac{1}{2} \\\\left( E \\\\left(\\\\bm{\\\\theta}+ (\\\\pi/2)\\\\bm{e}_{i,l} \\\\right) - E \\\\left( \\\\bm{\\\\theta}-(\\\\pi/2) \\\\bm{e}_{i,l} \\\\right) \\\\right),\\\\end{align*}where $i$ labels the qubits and $l$ cycles through all circuit layers, and $\\\\bm{e}_{i,l}$ is the unit vector.In order to approximate a single gradient, we need to estimate the difference of two energy expectation values $E(\\\\bm{\\\\theta}_+)=\\\\langle \\\\psi (\\\\bm{\\\\theta}_+) | H |\\\\psi (\\\\bm{\\\\theta}_+)\\\\rangle$ with $\\\\bm{\\\\theta}_+ = \\\\bm{\\\\theta} + (\\\\pi/2) \\\\bm{e}_{i,l}$ and $E(\\\\bm{\\\\theta}_-)=\\\\langle \\\\psi (\\\\bm{\\\\theta}_-) | H |\\\\psi (\\\\bm{\\\\theta}_-)\\\\rangle$ with $\\\\bm{\\\\theta}_- = \\\\bm{\\\\theta} - (\\\\pi/2) \\\\bm{e}_{i,l}$ (we suppress $i$ and $l$ indices in $\\\\bm \\\\theta_\\\\pm$ for the sake of brevity)',\n",
       " \"Typically, the Hamiltonian itself can be decomposed into a sum of $L$ `simple' terms: $H=\\\\sum_{l=1}^L h_l$, where often $L$ can be proportional to the number of qubits, $N$\",\n",
       " 'This allows to express the gradient as a linear combination of $2L$  expectation values,\\\\begin{equation}\\\\partial_{i,l} E \\\\left(\\\\bm{\\\\theta} \\\\right) =  \\\\frac{1}{2} \\\\sum_{l=1}^L \\\\left( \\\\langle \\\\psi (\\\\bm{\\\\theta}_+) | h_l | \\\\psi (\\\\bm{\\\\theta}_+) \\\\rangle - \\\\langle \\\\psi (\\\\bm{\\\\theta}_-) | h_l | \\\\psi (\\\\bm{\\\\theta}_-) \\\\rangle \\\\right), \\\\label{eq:gradient-reformulation}\\\\end{equation}each of which can be estimated by performing a collection of single-qubit Pauli measurements',\n",
       " 'If each term $h_l$ is supported on (at most) $k$-qubits, then Theorem~\\\\ref{thm:linear-shadows} applies',\n",
       " 'Performing$T \\\\approx 4^{k} \\\\ln (L/\\\\delta)/\\\\epsilon^2$randomized Pauli measurements on state $\\\\rho (\\\\bm{\\\\theta}_+)$ and $\\\\rho (\\\\bm{\\\\theta}_-)$ each allows us to $\\\\epsilon$-approximate all $2L$ simple terms in Eq.~\\\\eqref{eq:gradient-reformulation}.Unfortunately, approximation errors may accumulate when taking the sum over all $2L$ terms',\n",
       " 'Suppose that we obtain $\\\\epsilon$-accurate estimators $\\\\hat{E}_l (\\\\bm{\\\\theta}_\\\\pm)$ of contribution of the local Hamiltonian term to the energy $E_l (\\\\bm{\\\\theta}_\\\\pm)=\\\\langle \\\\psi (\\\\bm{\\\\theta}_\\\\pm)|h_l | \\\\psi (\\\\bm{\\\\theta}_{\\\\pm}) \\\\rangle$.A triangle inequality over all approximation errors then only produces\\\\begin{align*}& \\\\left| \\\\partial_{i,l}E(\\\\bm{\\\\theta})- \\\\hat{\\\\partial}_{i,l} E(\\\\bm{\\\\theta}) \\\\right| \\\\\\\\=&  \\\\frac{1}{2} \\\\left|\\\\sum_{l=1}^L \\\\left( \\\\hat{E}_l (\\\\bm{\\\\theta}_+) - E_l (\\\\bm{\\\\theta}_+) - \\\\hat{E}_l (\\\\bm{\\\\theta}_-) + E_l (\\\\bm{\\\\theta}_-\\\\right) \\\\right| \\\\\\\\\\\\leq &\\\\frac{1}{2}\\\\sum_{l=1}^L \\\\left| \\\\hat{E}_l (\\\\bm{\\\\theta}_+) - E_l (\\\\bm{\\\\theta}_+)\\\\right| + \\\\frac{1}{2}\\\\sum_{l=1}^L \\\\left| \\\\hat{E}_l (\\\\bm{\\\\theta}_-) - E_l (\\\\bm{\\\\theta}_-) \\\\right| = L \\\\epsilon.\\\\end{align*}This upper bound only equals $\\\\epsilon$ if we rescale the accuracy of original approximation  to $\\\\epsilon / L$.Inserting this rescaled accuracy into Theorem~\\\\ref{thm:linear-shadows} produces an overall measurement cost of\\\\begin{equation}T \\\\geq  \\\\frac{4^{k+1} L^2 \\\\ln (2L/\\\\delta)}{\\\\epsilon^2}',\n",
       " '\\\\label{eq:gradient-cost}\\\\end{equation}The number $L$ of terms in the Hamiltonian typically scales (at least) linearly in the number of qubits $N$',\n",
       " 'This implies that the measurement budget~\\\\eqref{eq:gradient-cost} required to (conservatively) estimate gradients scales quadratically in the system size and thus is parametrically larger than the (conservative) cost of estimating purities of size-$k$ subsystems~\\\\eqref{eq:sample-complexity-purity}',\n",
       " 'To obtain the full gradient $\\\\nabla_{\\\\bm{\\\\theta}} E(\\\\bm{\\\\theta})$ the procedure has to be repeated $p N$ times since the parameters-shift rule has to implemented for every variational parameter',\n",
       " 'It should be noted though, that in principle this can be computed in parallel, provided large enough (quantum) computational resources',\n",
       " 'For example, different NISQ computers could be used to estimate different gradient components at the same time.',\n",
       " 'The extra scaling with $L^2$ in Eq.~\\\\eqref{eq:gradient-cost} is a consequence of error accumulation',\n",
       " 'If we use the same measurement data to jointly estimate many Hamiltonian terms, then all these estimators become highly correlated',\n",
       " 'And the effect of outlier corruption -- which occurs naturally in empirical estimation -- becomes amplified',\n",
       " 'Here, we illustrate this subtlety by means of a simple example',\n",
       " 'Let $H=-J\\\\sum_{i=1}^{N-1} \\\\sigma_i^z \\\\sigma_{i+1}^z$  be the Ising Hamiltonian on a 1-D chain comprised of $N$ qubits ($L=N-1$)',\n",
       " 'Let us also assume that $N$ is even',\n",
       " 'This Hamiltonian is diagonal in the $Z$-basis $|i_1,\\\\ldots,i_N \\\\rangle = |i_1 \\\\rangle \\\\otimes \\\\cdots \\\\otimes |i_N \\\\rangle$ with $i_1,\\\\ldots,i_N \\\\in \\\\left\\\\{0,1\\\\right\\\\}$',\n",
       " 'So, in order to estimate $H$, it suffices to perform measurements solely in this basis',\n",
       " \"Born's rule asserts, that we observe bitstring $\\\\hat{s}_1,\\\\ldots,\\\\hat{s}_N$ with probability\\\\begin{equation*}\\\\mathrm{Pr} \\\\left[ \\\\hat{s}_1,\\\\ldots,\\\\hat{s}_N \\\\right] = \\\\langle \\\\hat{s}_1,\\\\ldots,\\\\hat{s}_N | \\\\rho | \\\\hat{s}_1,\\\\ldots,\\\\hat{s}_N \\\\rangle,\\\\end{equation*}where $\\\\rho$ denotes the underlying $N$-qubit state\",\n",
       " 'And, we can use these outcomes to directly estimate the total energy',\n",
       " 'It is easy to check that\\\\begin{align*}\\\\hat{E} =& \\\\langle \\\\hat{s}_1,\\\\ldots,\\\\hat{s}_N | H | \\\\hat{s}_1,\\\\ldots,\\\\hat{s}_N \\\\rangle \\\\\\\\=& - J \\\\sum_{i=1}^N \\\\langle \\\\hat{s}_i |\\\\sigma_i^z| \\\\hat{s}_i \\\\rangle \\\\langle \\\\hat{s}_{i+1}|\\\\sigma_{i+1}^z | \\\\hat{s}_{i+1}\\\\rangle\\\\end{align*}obeys $\\\\mathbb{E} \\\\left[ \\\\hat{E} \\\\right] = \\\\mathrm{tr} \\\\left( H \\\\rho \\\\right)$, regardless of the quantum state $\\\\rho$ in question',\n",
       " 'Also, estimating individual terms in this sum is both cheap and easy',\n",
       " 'Convergence of the sum, however, does depend on the underlying quantum state and the correlations within',\n",
       " \"To illustrate this, we choose $\\\\lambda \\\\in (0,1)$ and set\\\\begin{equation*}\\\\rho (\\\\lambda) = (1-\\\\lambda) |\\\\psi \\\\rangle \\\\! \\\\langle \\\\psi| + \\\\lambda |\\\\phi \\\\rangle \\\\! \\\\langle \\\\phi|,\\\\end{equation*}where $|\\\\psi \\\\rangle = |00 \\\\cdots 00 \\\\rangle$ is the Ising ground state and $|\\\\phi \\\\rangle = |01\\\\cdots 01\\\\rangle$ is a N\\\\'eel state\",\n",
       " 'These states obey $\\\\langle \\\\psi| H |\\\\psi \\\\rangle = - J(N-1)$ (ground state) and $\\\\langle \\\\phi |H| \\\\phi \\\\rangle = +J (N-1)$ (highest excited state), so\\\\begin{equation*}\\\\mathrm{tr}(H \\\\rho(\\\\lambda)) = -J(n-1) \\\\left(1-2\\\\lambda\\\\right).\\\\end{equation*}The task is to approximate this expectation value based on computational basis measurements',\n",
       " 'For each measurement, we either obtain outcome $0 \\\\cdots 0$ (with probability $1-p$) or outcome $01 \\\\cdots 01$ (with probability $p$)',\n",
       " 'This dichotomy extends to our estimator\\\\begin{equation*}\\\\hat{E} =\\\\begin{cases}\\\\langle \\\\psi | H |\\\\psi \\\\rangle = - J (N-1) &\\\\text{with prob.\\\\ $1-\\\\lambda$}, \\\\\\\\\\\\langle \\\\phi|H|\\\\phi \\\\rangle = +J (N-1) & \\\\text{with prob.\\\\ $\\\\lambda$}.\\\\end{cases}\\\\end{equation*}and we are effectively faced with estimating the (re-scaled) expectation value of a biased coin',\n",
       " 'The associated variance of such a coin toss can be easily computed and amounts to\\\\begin{align*}\\\\mathrm{Var} \\\\left[ \\\\hat{E}\\\\right] =& \\\\mathbb{E} \\\\left[ \\\\hat{E}^2 \\\\right] - \\\\left( \\\\mathbb{E} \\\\left[ \\\\hat{E}\\\\right]\\\\right)^2 = 4J^2 (N-1)^2 \\\\lambda (1-\\\\lambda).\\\\end{align*}Unless $\\\\lambda \\\\neq 0,1$ (where the variance vanishes), this variance it is proportional to $L^2=(N-1)^2$ and controls the rate of convergence',\n",
       " 'Asymptotically, a total number of \\\\begin{equation*}T \\\\geq \\\\mathrm{Var} \\\\left[ \\\\hat{E}\\\\right] /\\\\epsilon^2= 4J^2 L^2\\\\lambda(1-\\\\lambda)/\\\\epsilon^2=\\\\Omega (L^2/\\\\epsilon^2)\\\\end{equation*}independent coin tosses are necessary (and sufficient) to $\\\\epsilon$-approximate the true expectation value $\\\\mathbb{E} \\\\left[ \\\\hat{E}\\\\right] = \\\\mathrm{tr} \\\\left( \\\\rho (\\\\lambda) H \\\\right)$',\n",
       " 'This is a consequence of the central limit theorem and showcases that a measurement budget scaling with the number $L$ of Hamiltonian terms is unavoidable in general',\n",
       " 'We emphasize that this is a contrived worst-case argument that showcases how correlated measurements can affect the approximation quality of a sum of many simple terms, while each term individually is cheap and easy to evaluate',\n",
       " 'A generalization to the Heisenberg Hamiltonian considered in the main text, see Eq.~\\\\eqref{eq:heisenberg}, is straightforward',\n",
       " ' ',\n",
       " 'Theorem~\\\\ref{thm:linear-shadows} is a consequence of the following concentration inequality',\n",
       " 'Let $\\\\|O\\\\|_\\\\infty$ denote the operator/spectral norm of an observable',\n",
       " 'We will also use $\\\\| \\\\cdot \\\\|_1$ to denote the trace norm.\\\\begin{theorem} \\\\label{thm:linear-shadows-restatement}Fix a collection of $L$ range-$k$ observables $O_l$ with $\\\\|O_l\\\\|_\\\\infty \\\\leq 1$, a quantum state $\\\\rho$ and let $\\\\hat{\\\\rho} = \\\\frac{1}{T}\\\\sum_{t=1}^T \\\\hat{\\\\rho}^{(t)} $ be a classical shadow estimate thereof',\n",
       " 'Then, for $\\\\epsilon \\\\in (0,1)$,\\\\begin{equation*}\\\\mathrm{Pr}\\\\left[ \\\\max_{1 \\\\leq l \\\\leq L}\\\\left| \\\\mathrm{tr} \\\\left( O_l \\\\hat{\\\\rho})\\\\right) - \\\\mathrm{tr} \\\\left( O_l \\\\rho \\\\right) \\\\right| \\\\geq \\\\epsilon \\\\right] \\\\leq 2L \\\\exp \\\\left( - \\\\frac{\\\\epsilon^2 T}{4^{k+1}} \\\\right).\\\\end{equation*}\\\\end{theorem}This large deviation bound is a consequence of another well-known tail bound, see e.g.\\\\ Ref.~\\\\cite[Theorem 7.30]{rauhut2013book}.\\\\begin{theorem}[Bernstein inequality]Let $X^{(1)},\\\\ldots,X^{(T)}$ be independent, centered (i.e',\n",
       " '$\\\\mathbb{E}\\\\left[X_t \\\\right]=0$) random variables that obey $|X^{(t)}| \\\\leq R$ almost surely.Then, for $\\\\epsilon >0$\\\\begin{equation*}\\\\mathrm{Pr} \\\\left[ \\\\left| \\\\frac{1}{T}\\\\sum_{t=1}^T X^{(t)} \\\\right| \\\\geq \\\\epsilon \\\\right] \\\\leq 2  \\\\exp \\\\left( - \\\\frac{\\\\epsilon^2T^2/2}{\\\\sigma^2+RT\\\\epsilon} \\\\right),\\\\end{equation*}where $\\\\sigma^2 = \\\\sum_{t=1}^T \\\\mathbb{E} \\\\left[\\\\left(X^{(t)}\\\\right)^2\\\\right]$.\\\\end{theorem}\\\\begin{proof}[Proof of Theorem~\\\\ref{thm:linear-shadows-restatement}]Fix an observable $O=O_l$ with $1 \\\\leq l \\\\leq L$ and define $X^{(t)}=\\\\mathrm{tr} \\\\left( O \\\\hat{\\\\rho}^{(t)}\\\\right)-\\\\mathrm{tr} \\\\left( O \\\\rho \\\\right)$',\n",
       " 'Then, by construction of classical shadows, each $X^{(t)}$ is an independent random variable that also obeys $\\\\mathbb{E}\\\\left[X^{(t)}\\\\right]=0$, courtesy of Eq.~\\\\eqref{eq:shadow-average}',\n",
       " 'Next, let $A \\\\subseteq \\\\left\\\\{1,\\\\ldots,N\\\\right\\\\}$ with $|A|=k$ be the subsystem on which the range-$k$ observable acts nontrivially, i.e',\n",
       " \"$O = O_A \\\\otimes \\\\mathbb{I}_{\\\\neg A}$ and $\\\\|O \\\\|_\\\\infty = \\\\| O_A\\\\|_\\\\infty \\\\leq 1$.Then, Hoelder's inequality ($\\\\left|\\\\mathrm{tr} \\\\left( O_A \\\\rho_A \\\\right)\\\\right| \\\\leq \\\\|O_A \\\\|_\\\\infty \\\\|\\\\rho_A \\\\|_1$) asserts\\\\begin{align*}\\\\left|X^{(t)}\\\\right| =& \\\\left| \\\\mathrm{tr} \\\\left( O_A \\\\hat{\\\\rho}^{(t)}_A\\\\right) - \\\\mathrm{tr} \\\\left( O_A \\\\rho_A \\\\right) \\\\right| \\\\\\\\\\\\leq & \\\\left\\\\| O_A \\\\right\\\\|_\\\\infty \\\\left( \\\\left\\\\| \\\\rho_A \\\\right\\\\|_1 + \\\\left\\\\| \\\\hat{\\\\rho}_A^{(t)} \\\\right\\\\|_1 \\\\right) \\\\\\\\=& \\\\left\\\\| O_A \\\\right\\\\|_\\\\infty \\\\left( 1 + \\\\prod_{a \\\\in A} \\\\left\\\\| 3 |s_a^{(t)}\\\\rangle \\\\! \\\\langle s_a^{(t)}|-\\\\mathbb{I} \\\\right\\\\|_1 \\\\right) \\\\\\\\\\\\leq & \\\\left(1 + 2^{|A|}\\\\right) = 1+2^k =R,\\\\end{align*}where we have also used $\\\\|\\\\rho_A \\\\|_1 = \\\\mathrm{tr}(\\\\rho_A)=1$ and the specific form of subsystem classical shadows~\\\\eqref{eq:reduced-shadow} that factorizes nicely into tensor products\",\n",
       " 'Estimating the variance is more difficult by comparison',\n",
       " 'However, Ref.~\\\\cite[Proposition~S3]{huang2020predicting} asserts\\\\begin{equation*}\\\\mathbb{E} \\\\left[ \\\\left(X^{(t)}\\\\right)^2 \\\\right] \\\\leq \\\\|O \\\\|_{\\\\mathrm{shadow}}^2 \\\\leq 4^k \\\\|O \\\\|_\\\\infty = 4^k.\\\\end{equation*}In turn, $\\\\sigma^2 \\\\leq T 4^k$ and we conclude\\\\begin{align*}& \\\\mathrm{Pr} \\\\left[ \\\\left| \\\\mathrm{tr} \\\\left( O \\\\hat{\\\\rho}\\\\right) - \\\\mathrm{tr} \\\\left( O \\\\rho \\\\right) \\\\right| \\\\geq \\\\epsilon \\\\right] \\\\\\\\=& \\\\mathrm{Pr} \\\\left[ \\\\left| \\\\frac{1}{T} \\\\sum_{t=1}^T X^{(t)}\\\\right| \\\\geq \\\\epsilon \\\\right]  \\\\\\\\\\\\leq & 2 \\\\exp \\\\left( - \\\\frac{\\\\epsilon^2 T^2/2}{T4^k + (1+2^k)T \\\\epsilon} \\\\right)  \\\\\\\\\\\\leq & 2 \\\\exp \\\\left( - \\\\frac{\\\\epsilon^2 T}{4^{k+1}} \\\\right),\\\\end{align*}where the last line is a rough simplification of the exponent',\n",
       " \"Such a tail bound is valid for any $O=O_l$ and the advertised statement follows from taking a union bound (also known as Boole's inequality) over all possible deviations:\\\\begin{align*}& \\\\mathrm{Pr}\\\\left[ \\\\max_{1 \\\\leq l \\\\leq L}\\\\left| \\\\mathrm{tr} \\\\left( O_l \\\\hat{\\\\rho})\\\\right) - \\\\mathrm{tr} \\\\left( O_l \\\\rho \\\\right) \\\\right| \\\\geq \\\\epsilon \\\\right] \\\\\\\\\\\\leq & \\\\sum_{l=1}^L \\\\mathrm{Pr}\\\\left[\\\\left| \\\\mathrm{tr} \\\\left( O_l \\\\hat{\\\\rho})\\\\right) - \\\\mathrm{tr} \\\\left( O_l \\\\rho \\\\right) \\\\right| \\\\geq \\\\epsilon \\\\right] \\\\\\\\\\\\leq & 2L \\\\exp \\\\left( - \\\\frac{\\\\epsilon^2 T}{4^{k+1}} \\\\right).\\\\end{align*}\\\\end{proof}\",\n",
       " 'Here, we briefly review the notion of unitary $t$-designs.The Haar measure is the unique left/right invariant measure on the unitary group $U(d)$, where $d$ here stands for the dimension of the full Hilbert space, $d=2^N$',\n",
       " 'Unitary $t$-designs are ensembles of unitaries that approximate moments of the Haar measure',\n",
       " 'More precisely, let $\\\\mathcal{E}$ be an ensemble of unitaries, i.e.\\\\ a subset of $U(d)$ equipped with a probability measure',\n",
       " 'For an operator $O$ acting on the $t$-fold Hilbert space $\\\\mathcal{H}^{\\\\otimes t}$, the $t$-fold channel with respect to $\\\\mathcal{E}$ is defined as\\\\begin{equation}\\\\Phi^t_{\\\\mathcal{E}}(O) = \\\\int_{\\\\mathcal{E}} \\\\mathrm{d}U U^{\\\\otimes t} (O) U^{\\\\dagger \\\\otimes t}.\\\\end{equation}Essentially, we are asking when the average of an operator $O$ over the ensemble $\\\\mathcal{E}$ equals an average over the full unitary group',\n",
       " 'A unitary $t$-design~\\\\cite{dankert09unitary,gross07evenly} is an ensemble $\\\\mathcal{E}$ for which the $t$-fold channels are equal for all operators~$O$,$$\\\\Phi^t_{\\\\mathcal{E}} (O) = \\\\Phi^t_{\\\\mathop{\\\\rm{Haar}}} (O).$$Being a $t$-design means we exactly capture the first $t$ moments of the Haar measure with larger $t$ better approximating the full unitary group',\n",
       " 'There are known constructions of $t$-designs for $t=2$ and $t=3$~\\\\cite{dankert2009exact, cleve2016nearlinear, kueng2015qubit, webb2016clifford, zhu17clifford}',\n",
       " 'For $t=1$, it is known that any basis for the algebra of operators of $\\\\mathcal{H}$, including the Pauli group, is a $1$-design',\n",
       " 'In practice, one is more interested in when the ensemble of unitaries is close to forming a $t$-design',\n",
       " 'With this, given a tolerance $\\\\epsilon_t >0$ one refers to the ensemble $\\\\mathcal{E}$ as being an approximate $t$-design if $$\\\\norm{\\\\Phi^t_{\\\\mathcal{E}} - \\\\Phi^t_{\\\\mathop{\\\\rm{Haar}}} }_\\\\diamond \\\\leq \\\\epsilon_t,$$where $\\\\norm{\\\\cdot}_\\\\diamond$ is the diamond norm -- a worst-case distance measure that is very popular in quantum information theory, see e.g.\\\\ \\\\cite{watrous_2018}',\n",
       " 'In the quantum machine learning literature the distance between the two $t$-fold channels is known as the expressibility of the ensemble $\\\\mathcal{E}$~\\\\cite{holmes2021connecting}, the smaller the distance the more expressive the ensemble is',\n",
       " ' ',\n",
       " 'Random unitary operators have often been used to approximate late-time quantum dynamics',\n",
       " 'In the crudest approximation, it is assumed that the unitary matrix is directly drawn from the Haar measure',\n",
       " 'Although flawed -- energy, for instance, is not conserved -- this model has led to new insights into black hole physics~\\\\cite{page1993, hayden2007blackholes, sekino2008fastscramblers} and produced computable models of information spreading and entanglement dynamics~\\\\cite{nahum_2017_RUC, nahum_2018_RUC, hosur2016, pollman2018otocs}',\n",
       " 'In what follows, we consider a weaker situation where the random unitary operator is drawn from an ensemble $\\\\mathcal{E}$ forming a $2$-design, and focus on the entanglement properties of $N$-qubits random pure states \\\\be\\\\label{eq:random_state}|\\\\psi \\\\rangle = U|\\\\psi_0\\\\rangle,\\\\eewith $U\\\\sim \\\\mathcal{E}$',\n",
       " 'These results have been previously obtained, see for example~\\\\cite{popescu2006entanglement, oliveira2007,dahlsten2007typicalentanglement} and references therein',\n",
       " 'Given a bipartition $(A, \\\\neg{A})$ of the system, we begin by studying the distance of the reduced density matrix $\\\\rho_A$ to the maximally entangled state $\\\\rho^{\\\\infty}_{A} = \\\\mathbb{I}_A/d_A$, where $d_A$ is the dimension of the Hilbert space $\\\\mathcal{H}_A$ associated with region $A$',\n",
       " 'The full Hilbert space dimension is denoted by $d=2^N$.',\n",
       " 'Let us recall the following inequality relating the 1-norm (trace distance) $\\\\norm{M}_1 = \\\\tr \\\\sqrt{ M^\\\\dagger M}$, and the 2-norm (Frobenius norm) $\\\\norm{M}_2 = \\\\sqrt{\\\\tr (M^\\\\dagger M)}$\\\\begin{equation}\\\\norm{M}_2 \\\\leq  \\\\norm{M}_1  \\\\leq \\\\sqrt{d} \\\\norm{M}_2',\n",
       " '\\\\label{eq:norm_1and2} \\\\end{equation} We are interested in bounding $\\\\mathbb{E}_\\\\mathcal{E}\\\\big(\\\\norm{\\\\rho_A - \\\\mathbb{I}_A/d_A }_1\\\\big)^2$',\n",
       " \"To do so we first use Jensen's inequality and afterwards employ the inequality~\\\\eqref{eq:norm_1and2},\\\\be\\\\begin{split}\\\\mathbb{E}_\\\\mathcal{E}\\\\big(\\\\norm{\\\\rho_A - \\\\mathbb{I}_A/d_A }_1\\\\big) ^2 & \\\\leq \\\\mathbb{E}_\\\\mathcal{E}\\\\big(\\\\norm{\\\\rho_A - \\\\mathbb{I}_A/d_A}^2_1 \\\\big) \\\\\\\\& \\\\leq d_A \\\\mathbb{E}_\\\\mathcal{E}(\\\\norm{\\\\rho_A - \\\\mathbb{I}_A/d_A}^2_2).\\\\end{split}\\\\eeThe last term on the right hand side is related to the purity:\\\\be\\\\label{eq:bound_rhoA}\\\\mathbb{E}_\\\\mathcal{E}(\\\\norm{\\\\rho_A - \\\\mathbb{I}_A/d_A}^2_2)= \\\\mathbb{E}_\\\\mathcal{E}(\\\\tr \\\\rho^2_A) - 1/d_A .\\\\eeAs we see, the only non-trivial dependence on $U$ comes from the purity of the reduced density matrix\",\n",
       " 'Let $\\\\{ |I\\\\rangle = |i_A, j_{\\\\neg{A}}\\\\rangle \\\\}_{i,j}$ be the computational basis for the Hilbert space $\\\\mathcal{H} = \\\\mathcal{H}_{A} \\\\otimes \\\\mathcal{H}_{\\\\neg{A}}$ (such that it respects the bipartition).Let us now proceed with the calculation of the average purity',\n",
       " 'We first compute the reduced density matrix $\\\\rho_A$ and write it as a sum over products of matrix elements of the unitary operator $U$:\\\\begin{align*}    \\\\rho_A &= \\\\sum^{d_{\\\\neg{A}}}_{j_{\\\\neg{A}}} \\\\langle j_{\\\\neg{A}}| \\\\rho | j_{\\\\neg{A}} \\\\rangle = \\\\sum^{d_{\\\\neg{A}}}_{j_{\\\\neg{A}}} \\\\sum^{d}_{J,I} \\\\rho_{I,K}  \\\\langle j_{\\\\neg{A}}|  I \\\\rangle \\\\langle K | j_{\\\\neg{A}} \\\\rangle, \\\\\\\\    &= \\\\sum_{i_A, k_A} \\\\sum_{j_{\\\\neg{A}}} \\\\rho_{(i_A, j_{\\\\neg{A}}), (k_A, j_{\\\\neg{A}})} | i_A \\\\rangle \\\\langle k_A |, \\\\\\\\    &= \\\\sum_{i_A, k_A} \\\\sum_{j_{\\\\neg{A}}} U_{(i_A, j_{\\\\neg{A}}),(0,0)}U^*_{(k_A, j_{\\\\neg{A}}),(0,0)} | i_A \\\\rangle \\\\langle k_A |,\\\\end{align*}where the last line follows from Eq.~\\\\eqref{eq:random_state}',\n",
       " 'Afterwards, it can be easily verified that $\\\\tr (\\\\rho^2_A)$ reads\\\\begin{widetext}\\\\be\\\\begin{split}\\\\tr(\\\\rho^2_A) &= \\\\sum_{i_A, k_A} \\\\sum_{j_{\\\\neg{A}}, p_{\\\\neg{A}}} U_{(i_A, j_{\\\\neg{A}}), (0, 0)} U_{(k_A, p_{\\\\neg{A}}), (0,0)} U^*_{(k_A, j_{\\\\neg{A}}), (0,0)} U^*_{(i_A, p_{\\\\neg{A}}),(0,0)}.\\\\end{split}\\\\ee\\\\end{widetext}Using the following identities for the first and second moment of the unitary group endowed with the Haar measure\\\\begin{equation}\\\\label{eq:weingarten}\\\\begin{split}&\\\\int_{U(n)} dU_H U_{i,j} U^*_{i_1,j_1} = \\\\delta_{i,i_1} \\\\delta_{j,j_1}/d, \\\\\\\\& \\\\int_{U(n)} dU_H U_{i,j} U_{l,m}U^*_{i_1,j_1} U^*_{l_1,m_1} = \\\\\\\\ &\\\\frac{1}{d^2-1}(\\\\delta_{i,i_1}\\\\delta_{l,l_1}\\\\delta_{j,j_1}\\\\delta_{m,m_1}+  \\\\delta_{i,l_1}\\\\delta_{l,i_1}\\\\delta_{j,j_1}\\\\delta_{m,m_1}) - \\\\\\\\& \\\\frac{1}{d(d^2-1)} (\\\\delta_{i,i_1}\\\\delta_{l,l_1}\\\\delta_{j,m_1}\\\\delta_{m,j_1} + \\\\delta_{i,l_1}\\\\delta_{l,i_1}\\\\delta_{j,j_1}\\\\delta_{m,m_1}),\\\\end{split}\\\\end{equation}we get that the following simple expression for the expected purity\\\\be\\\\label{eq:average_purity}\\\\mathbb{E}_\\\\mathcal{E}(\\\\tr \\\\rho^2_A) = \\\\frac{d_A+d_{\\\\neg{A}}}{1+d_A d_{\\\\neg{A}}}.\\\\eeFinally, substituting Eq.~\\\\eqref{eq:average_purity} into Eq.~\\\\eqref{eq:bound_rhoA} we obtain\\\\be\\\\mathbb{E}_\\\\mathcal{E}\\\\big(\\\\norm{\\\\rho_A - \\\\mathbb{I}_A/d_A }_1\\\\big) \\\\leq \\\\sqrt{\\\\frac{d_A^2 -1}{d_Ad_{\\\\neg{A}} + 1}} \\\\sim \\\\mathcal{O}(\\\\sqrt{d_A/d_{\\\\neg{A}}})\\\\eeNote that the above result implies that when the complementary subsystem $\\\\neg{A}$ is (significantly) larger than $A$, the expected deviation of $\\\\rho_A$ from the maximally mixed state is exponentially small.',\n",
       " \"Let us now explore the average value of the second R\\\\'enyi entropy which, as mentioned in the main text, can be easily estimated using the classical shadows protocol by~\\\\citeauthor{huang2020predicting}\",\n",
       " \"Computing the exact average value of the second R\\\\'enyi is a complicated task\",\n",
       " 'Hence, we instead provide a lower and an upper bound for it',\n",
       " \"On one hand, via Jensen's inequality, we have that\\\\be-\\\\ln \\\\mathbb{E}_\\\\mathcal{E}(\\\\tr \\\\rho^2_A) \\\\leq \\\\mathbb{E}_\\\\mathcal{E}(S_2(\\\\rho_A)), \\\\eewhich changes the focus of our attention to the expectation value of the purity of the reduced density matrix $\\\\mathbb{E}_\\\\mathcal{E}(\\\\tr \\\\rho^2_A)$\",\n",
       " 'Using the result from the previous subsection Eq.~\\\\eqref{eq:average_purity} and taking the logarithm, we get the following lower bound\\\\be-\\\\ln \\\\mathbb{E}_\\\\mathcal{E}(\\\\tr \\\\rho^2_A)=-\\\\ln  \\\\frac{d_A+d_{\\\\neg{A}}}{1+d_A d_{\\\\neg{A}}}.\\\\eeTaking the large $d$ limit and writing everything in terms of $d_A/d_{\\\\neg{A}}$ we find\\\\be\\\\label{eq:S2_final}-\\\\ln \\\\mathbb{E}_\\\\mathcal{E}(\\\\tr \\\\rho^2_A) \\\\approx \\\\ln d_A - \\\\frac{d_A}{d_{\\\\neg{A}}} + \\\\mathcal{O}\\\\left(\\\\frac{d^2_A}{d^2_{\\\\neg{A}}}\\\\right).\\\\eeOn the other hand, we have that for any state $\\\\rho_A$ the following inequality holds $$S_2(\\\\rho_A) \\\\leq S(\\\\rho_A) = -\\\\ln \\\\rho_A \\\\tr \\\\rho_A,$$where $S(\\\\rho_A)$ is the von Neumann entropy of $\\\\rho_A$',\n",
       " \"Taking averages doesn't change this relation and we conclude $\\\\mathbb{E}_{\\\\mathcal{E}}(S_2(\\\\rho_A)) \\\\leq \\\\mathbb{E}_{\\\\mathcal{E}}(S(\\\\rho_A))$\",\n",
       " 'The expectation value of the von Neumann entropy is upper bounded by the \\\\emph{Page entropy}:\\\\beS^{\\\\text{Page}}(d_A, d) = \\\\frac{1}{\\\\ln 2}\\\\Big( -\\\\frac{d_A - 1}{2 }\\\\frac{d_A}{d} + \\\\sum_{j=d/d_A+1}^{d} \\\\frac{1}{j} \\\\Big).\\\\ee\\\\citeauthor{page1993} conjectured that this analytical formula accurately captures the von Neumann entropy of a Haar random state',\n",
       " 'This conjecture was subsequently proven in Ref.~\\\\cite{proofPage_1994}',\n",
       " \"Putting everything together, we obtain\\\\be-\\\\ln  \\\\frac{d_A+d_{\\\\neg{A}}}{1+d_A d_{\\\\neg{A}}} \\\\leq \\\\mathbb{E}_\\\\mathcal{E}(S_2(\\\\rho_A)) \\\\leq S^{\\\\text{Page}}(d_A, d).\\\\eeConsidering now that the number of qubits inside region $A$ is equal to $k$ and assuming that $d_A/d_{\\\\neg{A}} = 1/2^{N-2k} \\\\ll 1$ we arriveat the expression in Theorem~\\\\ref{thm:2-design}, that is\\\\bek \\\\ln 2 - \\\\frac{1}{2^{N-2k}} \\\\leq \\\\mathbb{E}_{\\\\mathcal{E}}(S_2) \\\\leq k \\\\ln 2 - \\\\frac{1}{2}\\\\frac{1}{2^{N-2k}}.\\\\eeWe see that whenever the unitary ensemble $\\\\mathcal{E}$ forms a $2$-design, the expected value of the second R\\\\'enyi entropy is close to the Page entropy\",\n",
       " 'Here we detail the derivation of Eq.~(\\\\ref{eq:trace_learning})',\n",
       " 'We first upper bound the trace distance via\\\\begin{align}\\\\label{eq:trace-distance}\\tT(\\\\rho_A, \\\\sigma_A) \\\\leq T(\\\\ket{\\\\psi}, \\\\ket{\\\\phi}) &= \\\\sqrt{1-f(\\\\ket{\\\\psi}, \\\\ket{\\\\phi})}, \\\\end{align}where $f$ stands for the pure state fidelity $f(\\\\ket{\\\\psi(\\\\bm{\\\\theta})}, \\\\ket{\\\\psi(\\\\bm{\\\\theta} +\\\\bm{\\\\delta})})=|\\\\bra{\\\\psi(\\\\bm{\\\\theta})} \\\\ket{\\\\psi(\\\\bm{\\\\theta} + \\\\bm{\\\\delta})}|^2$',\n",
       " 'Taylor expanding the pure state fidelity around $\\\\bm{\\\\theta}$ we get\\\\begin{equation}\\\\label{eq:fidelity-fisher}\\tf(\\\\ket{\\\\psi(\\\\bm{\\\\theta})}, \\\\ket{\\\\psi(\\\\bm{\\\\theta} +\\\\bm{\\\\delta})}) = 1-\\\\frac{1}{4}\\\\bm{\\\\delta}^T \\\\mathcal{F}(\\\\bm{\\\\theta}) \\\\bm{\\\\delta} + \\\\mathcal{O}(\\\\bm{\\\\delta}^4),\\\\end{equation}where $\\\\mathcal{F}(\\\\bm{\\\\theta})$ is the quantum Fisher information matrix (QFIM) given by\\\\begin{equation}\\\\label{eq:qfim_def}\\\\mathcal{F}_{i j}(\\\\bm{\\\\theta}) = 4 \\\\Re{\\\\bra{\\\\partial_i \\\\psi} \\\\ket{\\\\partial_j \\\\psi} - \\\\bra{\\\\partial_i \\\\psi} \\\\ket{\\\\psi} \\\\bra{\\\\psi} \\\\ket{\\\\partial_j \\\\psi}}.\\\\end{equation}Assuming $\\\\bm{\\\\delta} \\\\ll 1$ we can neglect higher order terms in $\\\\bm{\\\\delta}$ and so\\\\be\\t\\tT(\\\\rho_A, \\\\sigma_A) \\\\lesssim \\\\sqrt{\\\\frac{1}{4}\\\\bm{\\\\delta}^T \\\\mathcal{F}(\\\\bm{\\\\theta}) \\\\bm{\\\\delta}} =\\\\sqrt{\\\\frac{\\\\eta^2}{4} (\\\\nabla_{\\\\bm{\\\\theta}}E)^T \\\\mathcal{F}(\\\\bm{\\\\theta}) \\\\nabla_{\\\\bm{\\\\theta}}E}, \\\\ee\\twhere in the last equality we plugged in the parameter change under GD (Eq.~\\\\eqref{eq:gd}), $\\\\bm{\\\\delta}=-\\\\eta \\\\nabla_{\\\\bm{\\\\theta}} E$.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_text['full']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>title: Avoiding barren plateaus using classica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>author: Stefan H. Sack,Raimel A. Medina,Alexio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thanks: Equal contribution,Equal contribution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>email: stefan.sack@ist.ac.at,raimel.medina@ist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>affiliation: IST Austria, Am Campus 1, 3400 Kl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>This conjecture was subsequently proven in Ref...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>Putting everything together, we obtain\\be-\\ln ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>Here we detail the derivation of Eq.~(\\ref{eq:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>We first upper bound the trace distance via\\be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>Taylor expanding the pure state fidelity aroun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>406 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Phrase\n",
       "0    title: Avoiding barren plateaus using classica...\n",
       "1    author: Stefan H. Sack,Raimel A. Medina,Alexio...\n",
       "2        thanks: Equal contribution,Equal contribution\n",
       "3    email: stefan.sack@ist.ac.at,raimel.medina@ist...\n",
       "4    affiliation: IST Austria, Am Campus 1, 3400 Kl...\n",
       "..                                                 ...\n",
       "401  This conjecture was subsequently proven in Ref...\n",
       "402  Putting everything together, we obtain\\be-\\ln ...\n",
       "403  Here we detail the derivation of Eq.~(\\ref{eq:...\n",
       "404  We first upper bound the trace distance via\\be...\n",
       "405  Taylor expanding the pure state fidelity aroun...\n",
       "\n",
       "[406 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(final_text['full'], columns=['Phrase'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1328 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max tokens 1672\n"
     ]
    }
   ],
   "source": [
    "embedding_functions.save_embedding(df,'2201.08194')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read file from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import index\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('embeddings/text-search-babbage-doc-001_2201.08194.csv', index_col=0)\n",
    "df['similarity'] = df.similarity.apply(eval).apply(np.array)\n",
    "df['search'] = df.search.apply(eval).apply(np.array)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean 0.24322938048661125 1 std 0.25860110365730254 2 std 0.2739728268279938 Filter similarity: 0.2893445499986851\n",
      "This conjecture was subsequently proven in Ref.~\\cite{proofPage_1994} 0.2928347836741071\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import embedding_functions\n",
    "question = \"Conclusions \"\n",
    "df_sorted,newres = embedding_functions.search_phrases(df, question, how_many_std=3,connect_adj=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The algorithm employs  \\emph{classical shadow} estimation~\\cite{huang2020predicting} during the optimization process in order to efficiently estimate the expectation value of the cost function, its  gradients, and the second R\\'enyi entropy of small subsystems. The tracking of the second R\\'enyi entropy enabled by the classical shadows protocol allows for an efficient diagnosis of the WBP both at the initialization step  and during the optimization process of variational parameters\n",
      "False\n",
      "[]\n",
      "Using classical shadows we can efficiently check all subregions of size $k$ with only a $k \\ln(N)$-overhead in the measurement budget, see Appendix~\\ref{appx:shadows} for details\n",
      "True\n",
      "[]\n",
      "\\citeauthor{huang2020predicting} developed a more near-term friendly variant of this general idea known as prediction with \\emph{classical shadows}\n",
      "True\n",
      "[]\n",
      "   \\item (Implicitly) construct the $N$-qubit \\emph{classical shadow}    \\begin{equation}    \\hat{\\rho}^{(t)} (\\bm{\\theta}) =      \\bigotimes_{i=1}^N \\left( 3 |s_i^{(t)} \\rangle \\! \\langle s_i^{(t)}|- \\mathbb{I} \\right)\n",
      "False\n",
      "[]\n",
      "The tensor product structure of classical shadows~\\eqref{eq:shadow} plays nicely with taking partial traces.Let $A \\subseteq \\left\\{1,\\ldots,N\\right\\}$ be a collection of $|A|=k$ qubits\n",
      "False\n",
      "[]\n",
      "Then, with probability (at least) $1-\\delta$, classical shadows of size\\begin{equation*}T \\geq \\frac{4^{k+1} \\ln (2L/\\delta)}{\\epsilon^2}\\end{equation*}suffice to jointly estimate \\emph{all} $L$ expectation values up to additive accuracy $\\epsilon$\n",
      "False\n",
      "[]\n",
      "We will also use $\\| \\cdot \\|_1$ to denote the trace norm.\\begin{theorem} \\label{thm:linear-shadows-restatement}Fix a collection of $L$ range-$k$ observables $O_l$ with $\\|O_l\\|_\\infty \\leq 1$, a quantum state $\\rho$ and let $\\hat{\\rho} = \\frac{1}{T}\\sum_{t=1}^T \\hat{\\rho}^{(t)} $ be a classical shadow estimate thereof\n",
      "False\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import difflib\n",
    "\n",
    "\n",
    "complete_text = functions.extract_all_text(['papers/2201.08194/BP_shadows.tex']) \n",
    "for phrase in newres.Phrase:\n",
    "    print(phrase)\n",
    "    print(phrase in complete_text)\n",
    "    print(difflib.get_close_matches(phrase, complete_text,n=1, cutoff=0.1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Rect(142.029541015625, 461.955078125, 279.1746520996094, 471.9176940917969)]\n",
      "[Rect(176.78903198242188, 427.6661071777344, 219.81748962402344, 437.62872314453125)]\n",
      "[Rect(175.09535217285156, 415.607421875, 299.099853515625, 425.5700378417969), Rect(53.99996566772461, 427.0644226074219, 299.0500183105469, 437.02703857421875)]\n",
      "[Rect(81.68602752685547, 438.52142333984375, 299.1098327636719, 448.4840393066406), Rect(53.99996566772461, 449.9784240722656, 113.86521911621094, 459.9410400390625)]\n",
      "None\n",
      "None\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/gsilvi/Projects/Freaky Friday/PaperGenie/FileStripper.ipynb Cell 14'\u001b[0m in \u001b[0;36m<cell line: 42>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gsilvi/Projects/Freaky%20Friday/PaperGenie/FileStripper.ipynb#ch0000013?line=37'>38</a>\u001b[0m             phrase_split2 \u001b[39m=\u001b[39m phrase_split2[\u001b[39m1\u001b[39m:]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gsilvi/Projects/Freaky%20Friday/PaperGenie/FileStripper.ipynb#ch0000013?line=41'>42</a>\u001b[0m \u001b[39mfor\u001b[39;00m phrase_to_search \u001b[39min\u001b[39;00m newres\u001b[39m.\u001b[39mPhrase:  \n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/gsilvi/Projects/Freaky%20Friday/PaperGenie/FileStripper.ipynb#ch0000013?line=42'>43</a>\u001b[0m     highlight_pdf(doc, phrase_to_search)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gsilvi/Projects/Freaky%20Friday/PaperGenie/FileStripper.ipynb#ch0000013?line=45'>46</a>\u001b[0m \u001b[39m### OUTPUT\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gsilvi/Projects/Freaky%20Friday/PaperGenie/FileStripper.ipynb#ch0000013?line=46'>47</a>\u001b[0m doc\u001b[39m.\u001b[39msave(\u001b[39m\"\u001b[39m\u001b[39moutput.pdf\u001b[39m\u001b[39m\"\u001b[39m, garbage\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m, deflate\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, clean\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;32m/home/gsilvi/Projects/Freaky Friday/PaperGenie/FileStripper.ipynb Cell 14'\u001b[0m in \u001b[0;36mhighlight_pdf\u001b[0;34m(doc, phrase_to_search)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gsilvi/Projects/Freaky%20Friday/PaperGenie/FileStripper.ipynb#ch0000013?line=25'>26</a>\u001b[0m         phrase_found_1 \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gsilvi/Projects/Freaky%20Friday/PaperGenie/FileStripper.ipynb#ch0000013?line=26'>27</a>\u001b[0m \u001b[39mif\u001b[39;00m phrase_found_2 \u001b[39m==\u001b[39m \u001b[39mFalse\u001b[39;00m:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/gsilvi/Projects/Freaky%20Friday/PaperGenie/FileStripper.ipynb#ch0000013?line=27'>28</a>\u001b[0m     text_instances \u001b[39m=\u001b[39mpage\u001b[39m.\u001b[39;49msearch_for(phrase2)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gsilvi/Projects/Freaky%20Friday/PaperGenie/FileStripper.ipynb#ch0000013?line=28'>29</a>\u001b[0m     \u001b[39mif\u001b[39;00m text_instances \u001b[39m!=\u001b[39m []:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gsilvi/Projects/Freaky%20Friday/PaperGenie/FileStripper.ipynb#ch0000013?line=29'>30</a>\u001b[0m         \u001b[39mprint\u001b[39m(text_instances)\n",
      "File \u001b[0;32m~/miniforge3/envs/PaperGenie/lib/python3.9/site-packages/fitz/utils.py:407\u001b[0m, in \u001b[0;36msearch_for\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    405\u001b[0m tp \u001b[39m=\u001b[39m textpage\n\u001b[1;32m    406\u001b[0m \u001b[39mif\u001b[39;00m tp \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 407\u001b[0m     tp \u001b[39m=\u001b[39m page\u001b[39m.\u001b[39;49mget_textpage(clip\u001b[39m=\u001b[39;49mclip, flags\u001b[39m=\u001b[39;49mflags)  \u001b[39m# create TextPage\u001b[39;00m\n\u001b[1;32m    408\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mgetattr\u001b[39m(tp, \u001b[39m\"\u001b[39m\u001b[39mparent\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m!=\u001b[39m page:\n\u001b[1;32m    409\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mnot a textpage of this page\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/PaperGenie/lib/python3.9/site-packages/fitz/fitz.py:5588\u001b[0m, in \u001b[0;36mPage.get_textpage\u001b[0;34m(self, clip, flags, matrix)\u001b[0m\n\u001b[1;32m   5586\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_rotation(\u001b[39m0\u001b[39m)\n\u001b[1;32m   5587\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 5588\u001b[0m     textpage \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_textpage(clip, flags\u001b[39m=\u001b[39;49mflags, matrix\u001b[39m=\u001b[39;49mmatrix)\n\u001b[1;32m   5589\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m   5590\u001b[0m     \u001b[39mif\u001b[39;00m old_rotation \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniforge3/envs/PaperGenie/lib/python3.9/site-packages/fitz/fitz.py:5574\u001b[0m, in \u001b[0;36mPage._get_textpage\u001b[0;34m(self, clip, flags, matrix)\u001b[0m\n\u001b[1;32m   5573\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_textpage\u001b[39m(\u001b[39mself\u001b[39m, clip\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, flags\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, matrix\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m-> 5574\u001b[0m     val \u001b[39m=\u001b[39m _fitz\u001b[39m.\u001b[39;49mPage__get_textpage(\u001b[39mself\u001b[39;49m, clip, flags, matrix)\n\u001b[1;32m   5575\u001b[0m     val\u001b[39m.\u001b[39mthisown \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   5577\u001b[0m     \u001b[39mreturn\u001b[39;00m val\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    import fitz\n",
    "    pdfile = 'papers/2201.08194/BP_shadows.pdf'\n",
    "    ### READ IN PDF\n",
    "    doc = fitz.open(pdfile)\n",
    "\n",
    "    phrase_to_search = 'Variational quantum algorithms are promising algorithms for achieving \\quantum advantage on near-term devices.'\n",
    "\n",
    "    def highlight_pdf(doc, phrase_to_search):\n",
    "        middle =len(phrase_to_search)//2\n",
    "        phrase_split1 = phrase_to_search.split(' ')\n",
    "        phrase_split2 = phrase_split1.copy()\n",
    "        phrase_found_1 = False\n",
    "        phrase_found_2 = False\n",
    "        phrase2=None\n",
    "        while phrase_found_1 == False or phrase_found_2 == False: \n",
    "            phrase1 = ' '.join(phrase_split1)\n",
    "            phrase2 = ' '.join(phrase_split2)\n",
    "            for page in doc:\n",
    "                ### SEARCH\n",
    "                if phrase_found_1 == False:\n",
    "                    text_instances =page.search_for(phrase1)\n",
    "                    if text_instances != []:\n",
    "                        print(text_instances)\n",
    "                        highlight = page.add_highlight_annot(text_instances)\n",
    "                        highlight.update()\n",
    "                        phrase_found_1 = True\n",
    "                if phrase_found_2 == False:\n",
    "                    text_instances =page.search_for(phrase2)\n",
    "                    if text_instances != []:\n",
    "                        print(text_instances)\n",
    "                        highlight = page.add_highlight_annot(text_instances)\n",
    "                        highlight.update()\n",
    "                        phrase_found_2 = True\n",
    "                \n",
    "            if phrase_found_1 == False:\n",
    "                phrase_split1 = phrase_split1[:-1]\n",
    "            if phrase_found_2 == False:\n",
    "                phrase_split2 = phrase_split2[1:]\n",
    "        \n",
    "            \n",
    "\n",
    "    for phrase_to_search in newres.Phrase:  \n",
    "        highlight_pdf(doc, phrase_to_search)\n",
    "            \n",
    "\n",
    "    ### OUTPUT\n",
    "    doc.save(\"output.pdf\", garbage=4, deflate=True, clean=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Rect(118.00994873046875, 151.95025634765625, 311.6035461425781, 160.91665649414062)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try directly from pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "503"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#open a local pdf file and convert it with PDfFileReader\n",
    "pdf = PdfFileReader(open( 'papers/2201.08194/BP_shadows.pdf', \"rb\")) # open the pdf file, rb is for read binary, other options are r, w, a that mean read, write, append\n",
    "\n",
    "text = \"\"\n",
    "for page in range(pdf.getNumPages()-3):\n",
    "    text += pdf.getPage(page).extractText()\n",
    "    print(page)\n",
    "# text.replace('-\\n', '').replace('\\n', ' ').split('.')\n",
    "#keep only the elements longer than 5 characters\n",
    "phrases = [section for section in text.replace('-\\n', '').replace('i.e.', 'id est').replace('\\n', ' ').split('. ') if len(section) > 6]\n",
    "len(phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Medina,1,yAlexios A'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrases[2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('PaperGenie')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5ce793aca159cde98913a24cdfe3e728ef24ad8241460d78cf0550e564d457aa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
